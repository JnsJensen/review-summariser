{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "mps\n"
               ]
            }
         ],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import polars as pl\n",
            "import matplotlib.pyplot as plt\n",
            "import torch as th\n",
            "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
            "import re\n",
            "from enum import Enum\n",
            "import contractions as ct\n",
            "\n",
            "device = th.device(\"mps\") if th.backends.mps.is_available() else th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
            "\n",
            "if device.type == \"cuda\":\n",
            "    print(th.cuda.get_device_name(device))\n",
            "else:\n",
            "    print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_dir = \"datasets/\"\n",
            "\n",
            "# Dataset paths\n",
            "data_original = data_dir + \"full/\" # Use this for full dataset that contains all review matadata\n",
            "data_pruned = data_dir + \"pruned/\" # Only datasets with one number to the right side of it have a pruned version\n",
            "data_tokenized = data_dir + \"tokenized/\" # Only datasets with two numbers to the right side of it have a tokenized version\n",
            "\n",
            "full = \"All_Amazon_Review_5\" # 80 GB\n",
            "arts = \"Arts_Crafts_and_Sewing\" # 518 MB / 629 MB / 1.18 GB\n",
            "video = \"Amazon_Instant_Video_5\" # 28 MB\n",
            "gift = \"Gift_Cards_5\" # 0.88 MB"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "class DatasetType(Enum):\n",
            "    ORIGINAL = 0\n",
            "    PRUNED = 1\n",
            "    TOKENIZED = 2\n",
            "\n",
            "def prune(df: pd.DataFrame | pl.DataFrame) -> pl.DataFrame:\n",
            "    # list of unwanted summaries in lower case\n",
            "    summary_filter = [\"one star\", \"two stars\", \"three stars\", \"fours stars\", \"five stars\"]\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df = pl.DataFrame(df.dropna())\n",
            "    \n",
            "    assert(isinstance(df, pl.DataFrame))\n",
            "\n",
            "    df = df.filter(pl.col(\"summary\").apply(str.lower) != \"five stars\") \\\n",
            "           .filter(pl.col(\"summary\").apply(str.lower) != \"four stars\") \\\n",
            "           .filter(pl.col(\"summary\").apply(str.lower) != \"three stars\") \\\n",
            "           .filter(pl.col(\"summary\").apply(str.lower) != \"two stars\") \\\n",
            "           .filter(pl.col(\"summary\").apply(str.lower) != \"one star\")\n",
            "    return df\n",
            "\n",
            "def write_to_csv(df: pd.DataFrame | pl.DataFrame, path: str) -> None:\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df.to_csv(path + \".csv\", index=False)\n",
            "    elif isinstance(df, pl.DataFrame):\n",
            "        df.write_csv(path + \".csv\")\n",
            "\n",
            "def tokenize(df: pl.DataFrame, tokenizer: GPT2Tokenizer) -> pl.DataFrame:\n",
            "    t = lambda x: tokenizer.encode(x, add_special_tokens=True)\n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"reviewText\").apply(t),\n",
            "        pl.col(\"summary\").apply(t),\n",
            "        pl.exclude([\"reviewText\", \"summary\"])\n",
            "    ]).collect()\n",
            "    return df\n",
            "\n",
            "def load_dataset(dataset: str, dataset_type: DatasetType, keep_cols = [\"reviewText\", \"summary\", \"overall\"]) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        # return pl.read_json(data_original + dataset + \".json\", json_lines=True).select([keep_cols])\n",
            "        return pd.read_json(data_original + dataset + \".json\", lines=True)[keep_cols]\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        return pl.read_csv(data_pruned + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Int8})\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = pl.read_csv(data_tokenized + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Int8})\n",
            "        listify = lambda x: x.split(\"|\")\n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.col(\"summary\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        return df\n",
            "\n",
            "def save_dataset(df: pl.DataFrame, dataset: str, dataset_type: DatasetType) -> None:\n",
            "    if dataset_type == DatasetType.PRUNED:\n",
            "        write_to_csv(df, data_pruned + dataset)\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        stringify = lambda x: \"|\".join(list(x.cast(pl.Utf8)))\n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(stringify),\n",
            "            pl.col(\"summary\").apply(stringify),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        write_to_csv(df, data_tokenized + dataset)\n",
            "\n",
            "def preprocess(dataset: str, dataset_type: DatasetType, tokenizer, keep_cols = [\"reviewText\", \"summary\", \"overall\"], save_steps=True) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        df = load_dataset(dataset, dataset_type, keep_cols)\n",
            "        df = prune(df)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.PRUNED)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Prune and save\n",
            "df = load_dataset(gift, DatasetType.ORIGINAL)\n",
            "df = prune(df)\n",
            "save_dataset(df, gift, DatasetType.PRUNED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Not much to say, gift card is as good as cash!\n",
                  "gift card is as good as cash\n",
                  "5\n",
                  "shape: (5, 3)\n",
                  "┌────────────────────┬──────────────────────┬─────────┐\n",
                  "│ reviewText         ┆ summary              ┆ overall │\n",
                  "│ ---                ┆ ---                  ┆ ---     │\n",
                  "│ list[i64]          ┆ list[i64]            ┆ i8      │\n",
                  "╞════════════════════╪══════════════════════╪═════════╡\n",
                  "│ [1212, 373, ... 0] ┆ [2782, 10475, 0]     ┆ 5       │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5       │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [38, 2135]         ┆ [13681, 21208]       ┆ 5       │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [35700, 922, 0]    ┆ [35700, 922, 0]      ┆ 5       │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5       │\n",
                  "└────────────────────┴──────────────────────┴─────────┘\n",
                  "38|2135|2657|329|616|4957\n"
               ]
            }
         ],
         "source": [
            "# Tokenize and save\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "print(df[\"reviewText\"][-1])\n",
            "print(df[\"summary\"][-1])\n",
            "print(df[\"overall\"][-1])\n",
            "\n",
            "df = tokenize(df, tokenizer)\n",
            "print(df.tail())\n",
            "\n",
            "print(\"|\".join(list(df[\"reviewText\"][0].cast(pl.Utf8))))\n",
            "save_dataset(df, gift, DatasetType.TOKENIZED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        white-space: pre;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-top: 0;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-bottom: 0;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\" >\n",
                     "<small>shape: (5, 3)</small>\n",
                     "<thead>\n",
                     "<tr>\n",
                     "<th>\n",
                     "reviewText\n",
                     "</th>\n",
                     "<th>\n",
                     "summary\n",
                     "</th>\n",
                     "<th>\n",
                     "overall\n",
                     "</th>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "i8\n",
                     "</td>\n",
                     "</tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[1212, 373, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[2782, 10475, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "5\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[3673, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "5\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[38, 2135]\n",
                     "</td>\n",
                     "<td>\n",
                     "[13681, 21208]\n",
                     "</td>\n",
                     "<td>\n",
                     "5\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[35700, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[35700, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "5\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[3673, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "5\n",
                     "</td>\n",
                     "</tr>\n",
                     "</tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "shape: (5, 3)\n",
                     "┌────────────────────┬──────────────────────┬─────────┐\n",
                     "│ reviewText         ┆ summary              ┆ overall │\n",
                     "│ ---                ┆ ---                  ┆ ---     │\n",
                     "│ list[i64]          ┆ list[i64]            ┆ i8      │\n",
                     "╞════════════════════╪══════════════════════╪═════════╡\n",
                     "│ [1212, 373, ... 0] ┆ [2782, 10475, 0]     ┆ 5       │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5       │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [38, 2135]         ┆ [13681, 21208]       ┆ 5       │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [35700, 922, 0]    ┆ [35700, 922, 0]      ┆ 5       │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5       │\n",
                     "└────────────────────┴──────────────────────┴─────────┘"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Load the tokenized data\n",
            "# df = load_dataset(arts, DatasetType.TOKENIZED)\n",
            "df.tail()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Max length of review text:  566\n",
                  "Max length of summary:  28\n"
               ]
            }
         ],
         "source": [
            "# df = load_dataset(arts, DatasetType.TOKENIZED)\n",
            "\n",
            "# Find max length of review text with numpy\n",
            "max_review_len = np.max(list(df['reviewText'].apply(list).apply(len)))\n",
            "print(\"\\nMax length of review text: \", max_review_len)\n",
            "# Find max length of summary with numpy\n",
            "max_summary_len = np.max((list(df['summary'].apply(list).apply(len))))\n",
            "print(\"Max length of summary: \", max_summary_len)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 1535558 has no review tokens\n",
            "# summary: 1983|4846|317|321|343|29375|10318|282|1689|12|978|32|283|312|71|978|4627|259|993|978|29856|707|86|3301|5598|2623|532|49125|1415|7526|7420|9671\n",
            "# detokenize, find which data point it in the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# df = preprocess(arts, DatasetType.ORIGINAL, tokenizer)\n",
            "\n",
            "# Plot a distribution of review lengths with log scale\n",
            "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
            "\n",
            "r_counts, r_bins = np.histogram(df[\"reviewText\"].apply(len), bins=100)\n",
            "s_counts, s_bins = np.histogram(df[\"summary\"].apply(len), bins=100)\n",
            "\n",
            "r_vcounts = df[\"reviewText\"].apply(len).value_counts()\n",
            "s_vcounts = df[\"summary\"].apply(len).value_counts()\n",
            "r_vbins = list(r_vcounts[\"reviewText\"])\n",
            "s_vbins = list(s_vcounts[\"summary\"])\n",
            "\n",
            "log_yscale = True\n",
            "\n",
            "ax[0].hist(df[\"reviewText\"].apply(len), bins=range(np.min(r_vbins), np.max(r_vbins)), log=log_yscale)\n",
            "ax[0].set_title(\"Distribution of review lengths\")\n",
            "ax[0].set_xlabel(\"Review length\")\n",
            "ax[0].set_ylabel(\"Frequency\")\n",
            "ax[0].grid()\n",
            "\n",
            "ax[1].hist(df[\"summary\"].apply(len), bins=range(np.min(s_vbins), np.max(s_vbins)), log=log_yscale)\n",
            "ax[1].set_title(\"Distribution of summary lengths\")\n",
            "ax[1].set_xlabel(\"summary length\")\n",
            "ax[1].set_ylabel(\"Frequency\")\n",
            "ax[1].grid()\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "383993\n",
                  "1345\n"
               ]
            }
         ],
         "source": [
            "print(pl.DataFrame.estimated_size(df))\n",
            "print(len(df))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': tensor([[50257,  1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [50257,  1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [50257,  1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
                  "[' i am.', ' i am.', ' i am.']\n"
               ]
            }
         ],
         "source": [
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=\"<|pad|>\", bos_token=\"<|bos|>\", eos_token=\"<|eos|>\", unk_token=\"<|unk|>\", add_bos_token=True, add_prefix_space=True, trim_offsets=True)\n",
            "# t.add_special_tokens({'pad_token': '<pad>'})\n",
            "# t.add_special_tokens({'bos_token': '<bos>'})\n",
            "# t.add_special_tokens({'eos_token': '<eos>'})\n",
            "\n",
            "sentences = [\n",
            "    \"I'm.\",\n",
            "    \"i'm.\",\n",
            "    \"I am.\"\n",
            "]\n",
            "\n",
            "sentences = [\n",
            "    \" \".join([\n",
            "        ct.fix(word)\n",
            "        for word in sentence.split()\n",
            "    ]).lower()\n",
            "    for sentence in sentences\n",
            "]\n",
            "\n",
            "# sentences = \"one sentence\"\n",
            "\n",
            "tokenized = t(sentences, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=10, return_tensors = \"pt\")\n",
            "print(tokenized)\n",
            "\n",
            "decoding = lambda x, t, **kwargs : t.decode(x, kwargs) if isinstance(x, list) or isinstance(x, tuple) else t.batch_decode(x[\"input_ids\"], kwargs)\n",
            "\n",
            "# detokenized = t.batch_decode(tokenized[\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "detokenized = decoding(tokenized, t, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "print(detokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [],
         "source": [
            "# torch dataset from pandas dataframe\n",
            "# defines a voacbulary of words and converts the review text to a list of indices\n",
            "# beware of symbols like ., !, ? etc.\n",
            "# pad the review text and summary to max_review_len and max_summary_len respectively\n",
            "\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "\n",
            "class ReviewDataset(th.utils.data.Dataset):\n",
            "    def __init__(self, df: pl.DataFrame, tokenizer: GPT2Tokenizer, dataset_type = DatasetType.PRUNED, max_review_len = 2000, max_summary_len = 200, lower_case = True, device = \"cpu\"):\n",
            "        self.df = df\n",
            "        self.dataset_type = dataset_type\n",
            "        self.max_review_len = max_review_len\n",
            "        self.max_summary_len = max_summary_len\n",
            "        self.tokenizer = tokenizer\n",
            "        self.lower_case = lower_case\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.df)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        review = self.normalize_string(self.df[\"reviewText\"][idx], lower_case=self.lower_case)\n",
            "        summary = self.normalize_string(self.df[\"summary\"][idx], lower_case=self.lower_case)\n",
            "        rating = th.tensor(self.df[\"overall\"][idx])\n",
            "\n",
            "        # Tokenize the review and summary strings\n",
            "        review = self.tokenizer.encode(review, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_review_len, return_tensors = \"pt\").squeeze()\n",
            "        summary = self.tokenizer.encode(summary, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_summary_len, return_tensors = \"pt\").squeeze()\n",
            "        \n",
            "        return review, summary, rating\n",
            "    \n",
            "    def normalize_string(self, s, lower_case = True):\n",
            "        ns = \" \".join([ct.fix(word) for word in s.split()])\n",
            "        return ns.lower() if lower_case else ns\n",
            "    \n",
            "    def detokenize(self, x: th.Tensor):\n",
            "        return self.tokenizer.decode(x, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "it is a gift card, what else is there to say?\n",
                  "i love it\n",
                  "{'input_ids': tensor([[  270,   318,   257,  6979,  2657,    11,   644,  2073,   318,   612,\n",
                  "           284,   910,    30, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
                  "{'input_ids': tensor([[   72,  1842,   340, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0]])}\n"
               ]
            }
         ],
         "source": [
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "tokenizer.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n",
            "# tokenizer.add_special_tokens({\"eos_token\": \"<|eos|>\"})\n",
            "# tokenizer.add_special_tokens({\"bos_token\": \"<|bos|>\"})\n",
            "\n",
            "# I'm\n",
            "# i'm\n",
            "# I am\n",
            "\n",
            "idx = 38\n",
            "\n",
            "review = df[\"reviewText\"][idx]\n",
            "review = ct.fix(review.lower())\n",
            "summary = df[\"summary\"][idx]\n",
            "summary = ct.fix(summary.lower())\n",
            "\n",
            "print(review)\n",
            "print(summary)\n",
            "review_tokenized = tokenizer(review, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_review_len)\n",
            "summary_tokenized = tokenizer(summary, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_summary_len)\n",
            "\n",
            "print(review_tokenized)\n",
            "print(summary_tokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Review:  What is to go wrong with a gift card. As long as it enters into a person's account as a credit it is just what you paid for.\n",
                  "Summary:  gift card\n",
                  "Rating: 5\n"
               ]
            }
         ],
         "source": [
            "# test the dataset\n",
            "dataset = ReviewDataset(df, t, max_review_len = max_review_len, max_summary_len = max_summary_len, lower_case = False)\n",
            "\n",
            "data_idx = 45\n",
            "\n",
            "# decode\n",
            "print(f\"Review: {ReviewDataset.detokenize(dataset, dataset[data_idx][0])}\")\n",
            "print(f\"Summary: {ReviewDataset.detokenize(dataset, dataset[data_idx][1])}\")\n",
            "print(f\"Rating: {int(dataset[data_idx][2])}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Model\n",
            "uses context aware word embedding\n",
            "multi-task network\n",
            "\n",
            "Input: takes in a review string\n",
            "Task 1: output a summary string of the input review with a max length defined by the dataset\n",
            "Task 2: output a rating of the input review as a float 0-1\n",
            "\n",
            "Use an encoder decoder setup with one decoder for each task\n",
            "\"\"\"\n",
            "class Summariser(th.nn.Module):\n",
            "    def __init__(self, vocab_size, embedding_dim, max_review_len, max_summary_len):\n",
            "        super(Summariser, self).__init__()\n",
            "        self.vocab_size = vocab_size\n",
            "        self.embedding_dim = embedding_dim\n",
            "        self.max_review_len = max_review_len\n",
            "        self.max_summary_len = max_summary_len\n",
            "        self.embedding = th.nn.Embedding(vocab_size, embedding_dim)\n",
            "        self.encoder = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
            "        self.decoder1 = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, batch_first=True)\n",
            "        self.decoder2 = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, batch_first=True)\n",
            "        self.linear1 = th.nn.Linear(embedding_dim, vocab_size)\n",
            "        self.linear2 = th.nn.Linear(embedding_dim, 1)\n",
            "        self.softmax = th.nn.Softmax(dim=2)\n",
            "        self.sigmoid = th.nn.Sigmoid()\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.embedding(x)\n",
            "        x, _ = self.encoder(x)\n",
            "        x1, _ = self.decoder1(x)\n",
            "        x2, _ = self.decoder2(x)\n",
            "        x1 = self.linear1(x1)\n",
            "        x1 = self.softmax(x1)\n",
            "        x2 = self.linear2(x2)\n",
            "        x2 = self.sigmoid(x2)\n",
            "        return x1, x2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                  "Input length of input_ids is 11, but `max_length` is set to 11. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': [1212, 318, 262, 1336, 2420, 326, 345, 765, 284, 35743, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
                  "11\n"
               ]
            },
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'index_select'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [54], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(encoded_prompt[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(inputs[\u001b[39m0\u001b[39m]))\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     22\u001b[0m     inputs,\n\u001b[1;32m     23\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(inputs[\u001b[39m0\u001b[39;49m]) ,  \u001b[39m# Half the length of the encoded input text\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoded_prompt[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOutput: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Print the generated summary\u001b[39;00m\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:1535\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1526\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1527\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1532\u001b[0m )\n\u001b[1;32m   1534\u001b[0m \u001b[39m# 11. expand input_ids with `num_return_sequences` additional sequences per batch\u001b[39;00m\n\u001b[0;32m-> 1535\u001b[0m input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expand_inputs_for_generation(\n\u001b[1;32m   1536\u001b[0m     input_ids,\n\u001b[1;32m   1537\u001b[0m     expand_size\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m   1538\u001b[0m     is_encoder_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mis_encoder_decoder,\n\u001b[1;32m   1539\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1542\u001b[0m \u001b[39m# 12. run sample\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m   1544\u001b[0m     input_ids,\n\u001b[1;32m   1545\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1554\u001b[0m )\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:648\u001b[0m, in \u001b[0;36mGenerationMixin._expand_inputs_for_generation\u001b[0;34m(input_ids, expand_size, is_encoder_decoder, attention_mask, encoder_outputs, **model_kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m token_type_ids\u001b[39m.\u001b[39mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39;49mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m is_encoder_decoder:\n\u001b[1;32m    651\u001b[0m     \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'index_select'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "\n",
            "#from pytorch_transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "import torch\n",
            "\n",
            "# Set the device\n",
            "device = \"cpu\"\n",
            "\n",
            "# Load the GPT-2 model and tokenizer\n",
            "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "model = model.to(device)\n",
            "\n",
            "# Generate a summary\n",
            "#prompt = \"Airbags are safety devices that are installed in vehicles to protect passengers in the event of a collision. When a collision occurs, sensors detect the impact and deploy the airbag, which inflates quickly to cushion the passengers and prevent them from being thrown forward or to the side. Airbags are typically located in the steering wheel and dashboard for the driver, and in the doors and roof pillars for the passengers. They are designed to deploy in a specific sequence to maximize the protection they provide. Modern airbags use advanced sensors and algorithms to tailor their deployment to the specific type and severity of the collision.\"\n",
            "prompt = \"This is the full text that you want to summarize.\"\n",
            "encoded_prompt = tokenizer(prompt)\n",
            "print(encoded_prompt)\n",
            "inputs = torch.tensor(encoded_prompt[\"input_ids\"]).unsqueeze(0).to(device)\n",
            "\n",
            "outputs = model.generate(\n",
            "    inputs,\n",
            "    max_length=len(inputs) // 2,  # Half the length of the encoded input text\n",
            "    temperature=0.5,\n",
            "    top_k=50,\n",
            "    top_p=0.9,\n",
            "    repetition_penalty=1.0,\n",
            "    do_sample=True,\n",
            "    num_return_sequences=1,\n",
            "    attention_mask=encoded_prompt[\"attention_mask\"],\n",
            ")\n",
            "print(\"Output: \")\n",
            "# Print the generated summary\n",
            "print(tokenizer.decode(outputs[0]))\n",
            "print(f\"The origianl text is {len(encoded_prompt)} tokens long, and the generated summary is {len(outputs[0])} tokens long.\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'ne'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_text)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Set the attention mask and pad token id\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m attention_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49mne(tokenizer\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     15\u001b[0m pad_token_id \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mpad_token_id\n\u001b[1;32m     17\u001b[0m \u001b[39m# Generate a response from the model\u001b[39;00m\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ne'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
            "\n",
            "# Load the GPT-2 tokenizer\n",
            "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
            "\n",
            "# Load the GPT-2 model\n",
            "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
            "\n",
            "# Encode a text input\n",
            "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
            "input_ids = tokenizer.encode(input_text)\n",
            "\n",
            "# Set the attention mask and pad token id\n",
            "attention_mask = input_ids.(tokenizer.pad_token_id).long()\n",
            "pad_token_id = tokenizer.pad_token_id\n",
            "\n",
            "# Generate a response from the model\n",
            "outputs = model.generate(\n",
            "    input_ids=input_ids,\n",
            "    attention_mask=attention_mask,\n",
            "    pad_token_id=pad_token_id\n",
            ")\n",
            "\n",
            "# Print the encoded text\n",
            "print(outputs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Dataset preparation\n",
            "Use the ReviewDataset to create a DataLoader\n",
            "Splitting the train, validation, and test sets\n",
            "\"\"\"\n",
            "# initialise the dataset\n",
            "dataset = ReviewDataset(df)\n",
            "dataset_size = len(dataset)\n",
            "\n",
            "# shrink dataset for testing\n",
            "dataset_size = 500\n",
            "dataset = th.utils.data.Subset(dataset, range(dataset_size))\n",
            "\n",
            "# split the dataset\n",
            "train_size = int(0.8 * dataset_size)\n",
            "val_size = int(0.1 * dataset_size)\n",
            "test_size = dataset_size - train_size - val_size\n",
            "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
            "\n",
            "# create the dataloaders\n",
            "batch_size = 32\n",
            "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
            "val_loader = th.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
            "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([32, 18152]) torch.Size([32]) torch.Size([32, 151])\n"
               ]
            }
         ],
         "source": [
            "# test the dataloader\n",
            "train_loader_iter = iter(train_loader)\n",
            "x, y, z = next(train_loader_iter)\n",
            "print(x.shape, y.shape, z.shape)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Training\n",
            "\"\"\"\n",
            "\"\"\" # initialise the model\n",
            "# take into account if it is a subset of the dataset\n",
            "model = Summariser(dataset.dataset.vocab_size, 256, max_review_len, max_summary_len)\n",
            "model = model.to(device)\n",
            "\n",
            "# define the loss functions\n",
            "loss_fn1 = th.nn.CrossEntropyLoss()\n",
            "loss_fn2 = th.nn.BCELoss()\n",
            "\n",
            "# define the optimiser\n",
            "optimiser = th.optim.Adam(model.parameters(), lr=0.001)\n",
            "\n",
            "# define the number of epochs\n",
            "epochs = 10\n",
            "\n",
            "# train the model\n",
            "for epoch in range(epochs):\n",
            "    for review, rating, summary in train_loader:\n",
            "        # zero the gradients\n",
            "        optimiser.zero_grad()\n",
            "\n",
            "        # forward pass\n",
            "        y_pred1, y_pred2 = model(review)\n",
            "\n",
            "        # calculate the loss\n",
            "        loss1 = loss_fn1(y_pred1, summary)\n",
            "        loss2 = loss_fn2(y_pred2, rating.unsqueeze(1).float())\n",
            "        loss = loss1 + loss2\n",
            "\n",
            "        # backward pass\n",
            "        loss.backward()\n",
            "\n",
            "        # update the weights\n",
            "        optimiser.step()\n",
            "\n",
            "    # print the loss\n",
            "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}') \"\"\"\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.6 ('pytorch1.13')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.6"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "74ce01c583b9da8e861aa1ee054dcef8ec2fe05bc1a1578aa65fd6e69a36df1a"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}