{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cpu\n"
               ]
            }
         ],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import polars as pl\n",
            "import matplotlib.pyplot as plt\n",
            "import torch as th\n",
            "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config, GPT2LMHeadModel, GPT2DoubleHeadsModel\n",
            "import re\n",
            "from enum import Enum\n",
            "import contractions as ct\n",
            "from torch import nn\n",
            "\n",
            "device = th.device(\"mps\") if th.backends.mps.is_available() else th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
            "\n",
            "if device.type == \"cuda\":\n",
            "    print(th.cuda.get_device_name(device))\n",
            "else:\n",
            "    print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_dir = \"datasets/\"\n",
            "\n",
            "# Dataset paths\n",
            "data_original = data_dir + \"full/\" # Use this for full dataset that contains all review matadata\n",
            "data_pruned = data_dir + \"pruned/\" # Only datasets with one number to the right side of it have a pruned version\n",
            "data_tokenized = data_dir + \"tokenized/\" # Only datasets with two numbers to the right side of it have a tokenized version\n",
            "\n",
            "full = \"All_Amazon_Review_5\" # 80 GB\n",
            "arts = \"Arts_Crafts_and_Sewing\" # 518 MB / 629 MB / 1.18 GB\n",
            "video = \"Amazon_Instant_Video_5\" # 28 MB\n",
            "gift = \"Gift_Cards_5\" # 0.88 MB"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'g k k'"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "string = \"g    k  k\"\n",
            "re.sub(r\"\\s+\", \" \", string)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "DatasetType enum\n",
            "- ORIGINAL: The original json dataset\n",
            "- PRUNED: The pruned csv dataset\n",
            "- TOKENIZED: The tokenized csv dataset\n",
            "\"\"\"\n",
            "class DatasetType(Enum):\n",
            "    ORIGINAL = 0\n",
            "    PRUNED = 1\n",
            "    TOKENIZED = 2\n",
            "\n",
            "listify = lambda x: x.split(\"|\")\n",
            "stringify = lambda x: \"|\".join(list(x.cast(pl.Utf8)))\n",
            "\n",
            "\"\"\"\n",
            "Normalizes strings by:\n",
            "- Removing double spaces\n",
            "- Converting to lower case\n",
            "- Expanding contractions\n",
            "\"\"\"\n",
            "def normalize_text(text: str) -> str:\n",
            "    return re.sub(r\"\\s+\", \" \", ct.fix(text.lower()))\n",
            "\n",
            "\"\"\"\n",
            "Normalizes the reviewText and summary columns of a dataframe by:\n",
            "- Using normalize_text on the 'reviewText' and 'summary' columns\n",
            "\"\"\"\n",
            "def normalize_text_df(df: pl.DataFrame) -> pl.DataFrame:\n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"reviewText\").apply(normalize_text),\n",
            "        pl.col(\"summary\").apply(normalize_text),\n",
            "        pl.exclude([\"reviewText\", \"summary\"])\n",
            "    ]).collect()\n",
            "    return df\n",
            "\n",
            "\"\"\"\n",
            "Prunes the dataset by:\n",
            "- Removing reviews with a summary of \"five stars\", \"four stars\", \"three stars\", \"two stars\", or \"one star\n",
            "- Normalizing the reviewText and summary columns by the use of normalize_text_df\n",
            "- Converting the overall column to a float between 0 and 1\n",
            "\"\"\"\n",
            "def prune(df: pd.DataFrame | pl.DataFrame) -> pl.DataFrame:\n",
            "    # list of unwanted summaries in lower case\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df = pl.DataFrame(df.dropna())\n",
            "    assert(isinstance(df, pl.DataFrame))\n",
            "\n",
            "    df = normalize_text_df(df)\n",
            "\n",
            "    df = df.filter(pl.col(\"summary\") != \"five stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"four stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"three stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"two stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"one star\")\n",
            "    \n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"overall\").apply(lambda x: int(x)/5),\n",
            "        pl.exclude([\"overall\"])\n",
            "    ]).collect()\n",
            "    return df.select([pl.col(\"reviewText\"), pl.col(\"summary\"), pl.col(\"overall\")])\n",
            "\n",
            "\"\"\"\n",
            "Writes a dataframe to a csv file\n",
            "- Distinguishes between polars and pandas dataframes\n",
            "\"\"\"\n",
            "def write_to_csv(df: pd.DataFrame | pl.DataFrame, path: str) -> None:\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df.to_csv(path + \".csv\", index=False)\n",
            "    elif isinstance(df, pl.DataFrame):\n",
            "        df.write_csv(path + \".csv\")\n",
            "\n",
            "\"\"\"\n",
            "Tokenizes the reviewText and summary columns of a dataframe by:\n",
            "- Using the tokenizer to encode the 'reviewText' and 'summary' columns\n",
            "\"\"\"\n",
            "def tokenize(df: pl.DataFrame, tokenizer: GPT2Tokenizer) -> pl.DataFrame:\n",
            "    t = lambda x: tokenizer.encode(x, add_special_tokens=True)\n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"reviewText\").apply(t),\n",
            "        pl.col(\"summary\").apply(t),\n",
            "        pl.exclude([\"reviewText\", \"summary\"])\n",
            "    ]).collect()\n",
            "    return df\n",
            "\n",
            "\"\"\"\n",
            "Loads a dataset from a csv file\n",
            "- Distinguishes between polars and pandas dataframes\n",
            "- Distinguishes between the original, pruned, and tokenized datasets\n",
            "\"\"\"\n",
            "def load_dataset(dataset: str, dataset_type: DatasetType, keep_cols = [\"reviewText\", \"summary\", \"overall\"]) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        # return pl.read_json(data_original + dataset + \".json\", json_lines=True).select([keep_cols])\n",
            "        return pd.read_json(data_original + dataset + \".json\", lines=True)[keep_cols]\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        return pl.read_csv(data_pruned + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Float32})\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = pl.read_csv(data_tokenized + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Float32})\n",
            "        \n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.col(\"summary\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        return df\n",
            "\n",
            "\"\"\"\n",
            "Saves a dataset to a csv file\n",
            "- Distinguishes between the pruned and tokenized datasets\n",
            "\"\"\"\n",
            "def save_dataset(df: pl.DataFrame, dataset: str, dataset_type: DatasetType) -> None:\n",
            "    if dataset_type == DatasetType.PRUNED:\n",
            "        write_to_csv(df, data_pruned + dataset)\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        \n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(stringify),\n",
            "            pl.col(\"summary\").apply(stringify),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        write_to_csv(df, data_tokenized + dataset)\n",
            "\n",
            "\"\"\"\n",
            "Preprocesses a dataset by:\n",
            "- Loading the dataset\n",
            "- Pruning the dataset\n",
            "- Tokenizing the dataset\n",
            "\"\"\"\n",
            "def preprocess(dataset: str, dataset_type: DatasetType, tokenizer, keep_cols = [\"reviewText\", \"summary\", \"overall\"], save_steps=True) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        df = load_dataset(dataset, dataset_type, keep_cols)\n",
            "        df = prune(df)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.PRUNED)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 94,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Prune and save\n",
            "df = load_dataset(gift, DatasetType.ORIGINAL)\n",
            "df = prune(df)\n",
            "save_dataset(df, gift, DatasetType.PRUNED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 95,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "not much to say, gift card is as good as cash!\n",
                  "gift card is as good as cash\n",
                  "1.0\n",
                  "shape: (5, 3)\n",
                  "┌────────────────────┬──────────────────────┬─────────┐\n",
                  "│ reviewText         ┆ summary              ┆ overall │\n",
                  "│ ---                ┆ ---                  ┆ ---     │\n",
                  "│ list[i64]          ┆ list[i64]            ┆ f32     │\n",
                  "╞════════════════════╪══════════════════════╪═════════╡\n",
                  "│ [5661, 373, ... 0] ┆ [7079, 540, 0]       ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [70, 2135]         ┆ [18223, 6979]        ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [37784, 922, 0]    ┆ [37784, 922, 0]      ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                  "└────────────────────┴──────────────────────┴─────────┘\n",
                  "70|2135|2657|329|616|4957\n"
               ]
            }
         ],
         "source": [
            "# Tokenize and save\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "print(df[\"reviewText\"][-1])\n",
            "print(df[\"summary\"][-1])\n",
            "print(df[\"overall\"][-1])\n",
            "\n",
            "df = tokenize(df, tokenizer)\n",
            "print(df.tail())\n",
            "\n",
            "print(\"|\".join(list(df[\"reviewText\"][0].cast(pl.Utf8))))\n",
            "save_dataset(df, gift, DatasetType.TOKENIZED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        white-space: pre;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-top: 0;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-bottom: 0;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "<small>shape: (5, 3)</small>\n",
                     "<thead>\n",
                     "<tr>\n",
                     "<th>\n",
                     "reviewText\n",
                     "</th>\n",
                     "<th>\n",
                     "summary\n",
                     "</th>\n",
                     "<th>\n",
                     "overall\n",
                     "</th>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "f32\n",
                     "</td>\n",
                     "</tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[1212, 373, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[2782, 10475, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "5.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[3673, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "5.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[38, 2135]\n",
                     "</td>\n",
                     "<td>\n",
                     "[13681, 21208]\n",
                     "</td>\n",
                     "<td>\n",
                     "5.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[35700, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[35700, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "5.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[3673, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "5.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "</tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "shape: (5, 3)\n",
                     "┌────────────────────┬──────────────────────┬─────────┐\n",
                     "│ reviewText         ┆ summary              ┆ overall │\n",
                     "│ ---                ┆ ---                  ┆ ---     │\n",
                     "│ list[i64]          ┆ list[i64]            ┆ f32     │\n",
                     "╞════════════════════╪══════════════════════╪═════════╡\n",
                     "│ [1212, 373, ... 0] ┆ [2782, 10475, 0]     ┆ 5.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [38, 2135]         ┆ [13681, 21208]       ┆ 5.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [35700, 922, 0]    ┆ [35700, 922, 0]      ┆ 5.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [3673, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 5.0     │\n",
                     "└────────────────────┴──────────────────────┴─────────┘"
                  ]
               },
               "execution_count": 14,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Load the tokenized data\n",
            "df = load_dataset(arts, DatasetType.TOKENIZED)\n",
            "df.tail()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Max length of review text:  566\n",
                  "Max length of summary:  28\n"
               ]
            }
         ],
         "source": [
            "# df = load_dataset(arts, DatasetType.TOKENIZED)\n",
            "\n",
            "# Find max length of review text with numpy\n",
            "max_review_len = np.max(list(df['reviewText'].apply(list).apply(len)))\n",
            "print(\"\\nMax length of review text: \", max_review_len)\n",
            "# Find max length of summary with numpy\n",
            "max_summary_len = np.max((list(df['summary'].apply(list).apply(len))))\n",
            "print(\"Max length of summary: \", max_summary_len)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 99,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# df = preprocess(arts, DatasetType.ORIGINAL, tokenizer)\n",
            "\n",
            "# Plot a distribution of review lengths with log scale\n",
            "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
            "\n",
            "r_counts, r_bins = np.histogram(df[\"reviewText\"].apply(len), bins=100)\n",
            "s_counts, s_bins = np.histogram(df[\"summary\"].apply(len), bins=100)\n",
            "\n",
            "r_vcounts = df[\"reviewText\"].apply(len).value_counts()\n",
            "s_vcounts = df[\"summary\"].apply(len).value_counts()\n",
            "r_vbins = list(r_vcounts[\"reviewText\"])\n",
            "s_vbins = list(s_vcounts[\"summary\"])\n",
            "\n",
            "log_yscale = True\n",
            "\n",
            "ax[0].hist(df[\"reviewText\"].apply(len), bins=range(np.min(r_vbins), np.max(r_vbins)), log=log_yscale)\n",
            "ax[0].set_title(\"Distribution of review lengths\")\n",
            "ax[0].set_xlabel(\"Review length\")\n",
            "ax[0].set_ylabel(\"Frequency\")\n",
            "ax[0].grid()\n",
            "\n",
            "ax[1].hist(df[\"summary\"].apply(len), bins=range(np.min(s_vbins), np.max(s_vbins)), log=log_yscale)\n",
            "ax[1].set_title(\"Distribution of summary lengths\")\n",
            "ax[1].set_xlabel(\"summary length\")\n",
            "ax[1].set_ylabel(\"Frequency\")\n",
            "ax[1].grid()\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 100,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "388028\n",
                  "1345\n"
               ]
            }
         ],
         "source": [
            "print(pl.DataFrame.estimated_size(df))\n",
            "print(len(df))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 104,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': tensor([[ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
                  "[' i am.', ' i am.', ' i am.']\n"
               ]
            }
         ],
         "source": [
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=\"<|pad|>\", bos_token=\"<|bos|>\", eos_token=\"<|eos|>\", unk_token=\"<|unk|>\", add_bos_token=False, add_prefix_space=True, trim_offsets=True)\n",
            "# t.add_special_tokens({'pad_token': '<pad>'})\n",
            "# t.add_special_tokens({'bos_token': '<bos>'})\n",
            "# t.add_special_tokens({'eos_token': '<eos>'})\n",
            "\n",
            "sentences = [\n",
            "    \"I'm.\",\n",
            "    \"i'm.\",\n",
            "    \"I am.\"\n",
            "]\n",
            "\n",
            "sentences = [\n",
            "    \" \".join([\n",
            "        ct.fix(word)\n",
            "        for word in sentence.split()\n",
            "    ]).lower()\n",
            "    for sentence in sentences\n",
            "]\n",
            "\n",
            "# sentences = \"one sentence\"\n",
            "\n",
            "tokenized = t(sentences, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=10, return_tensors = \"pt\")\n",
            "print(tokenized)\n",
            "\n",
            "decoding = lambda x, t, **kwargs : t.decode(x, kwargs) if isinstance(x, list) or isinstance(x, tuple) else t.batch_decode(x[\"input_ids\"], kwargs)\n",
            "\n",
            "# detokenized = t.batch_decode(tokenized[\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "detokenized = decoding(tokenized, t, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "print(detokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# torch dataset from pandas dataframe\n",
            "# defines a voacbulary of words and converts the review text to a list of indices\n",
            "# beware of symbols like ., !, ? etc.\n",
            "# pad the review text and summary to max_review_len and max_summary_len respectively\n",
            "\n",
            "\"\"\"\n",
            "ReviewDataset pytorch dataset interface\n",
            "- expects a polars dataframe with columns reviewText, summary, overall\n",
            "- expects it in the DatasetType.PRUNED format\n",
            "- expects a GPT2Tokenizer\n",
            "\"\"\"\n",
            "class ReviewDataset(th.utils.data.Dataset):\n",
            "    def __init__(self, df: pl.DataFrame, tokenizer: GPT2Tokenizer, dataset_type = DatasetType.PRUNED, max_review_len = 2000, max_summary_len = 200, lower_case = True, device = \"cpu\"):\n",
            "        self.df = df\n",
            "        self.dataset_type = dataset_type\n",
            "        self.max_review_len = max_review_len\n",
            "        self.max_summary_len = max_summary_len\n",
            "        self.tokenizer = tokenizer\n",
            "        self.lower_case = lower_case\n",
            "        self.device = device\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.df)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        review = self.df[\"reviewText\"][idx]\n",
            "        summary = self.df[\"summary\"][idx]\n",
            "        rating = th.tensor(self.df[\"overall\"][idx])\n",
            "\n",
            "        # Tokenize the review and summary strings\n",
            "        review = self.tokenizer.encode(review, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_review_len, return_tensors = \"pt\").squeeze()\n",
            "        summary = self.tokenizer.encode(summary, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_summary_len, return_tensors = \"pt\").squeeze()\n",
            "\n",
            "        # move tensors to device\n",
            "        review = review.to(self.device)\n",
            "        summary = summary.to(self.device)\n",
            "        rating = rating.to(self.device)\n",
            "        \n",
            "        return review, summary, rating\n",
            "    \n",
            "    def detokenize(self, x: th.Tensor):\n",
            "        return self.tokenizer.decode(x, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(tensor([  644,   318,   284,   467,  2642,   351,   257,  6979,  2657,    13,\n",
                  "          355,   890,   355,   340, 14170,   656,   257,  1048,   338,  1848,\n",
                  "          355,   257,  3884,   340,   318,   655,   644,   345,  3432,   329,\n",
                  "           13, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259]), tensor([ 6979,  2657, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
                  "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]), tensor(1.))\n",
                  " what is to go wrong with a gift card. as long as it enters into a person's account as a credit it is just what you paid for.\n"
               ]
            }
         ],
         "source": [
            "# test the ReviewDataset class\n",
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=\"<|pad|>\", bos_token=\"<|bos|>\", eos_token=\"<|eos|>\", unk_token=\"<|unk|>\", add_bos_token=False, add_prefix_space=True, trim_offsets=True)\n",
            "idx = 45\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "dataset = ReviewDataset(df, t, max_review_len=max_review_len, max_summary_len=max_summary_len, device=device)\n",
            "print(dataset[45])\n",
            "\n",
            "# test the detokenize method\n",
            "print(dataset.detokenize(dataset[45][0]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 80,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "it is a gift card, what else is there to say?\n",
                  "i love it\n",
                  "{'input_ids': tensor([[  270,   318,   257,  6979,  2657,    11,   644,  2073,   318,   612,\n",
                  "           284,   910,    30, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0]])}\n",
                  "{'input_ids': tensor([[   72,  1842,   340, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
                  "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                  "         0, 0, 0, 0]])}\n"
               ]
            }
         ],
         "source": [
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "tokenizer.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n",
            "# tokenizer.add_special_tokens({\"eos_token\": \"<|eos|>\"})\n",
            "# tokenizer.add_special_tokens({\"bos_token\": \"<|bos|>\"})\n",
            "\n",
            "# I'm\n",
            "# i'm\n",
            "# I am\n",
            "\n",
            "idx = 38\n",
            "\n",
            "review = df[\"reviewText\"][idx]\n",
            "review = ct.fix(review.lower())\n",
            "summary = df[\"summary\"][idx]\n",
            "summary = ct.fix(summary.lower())\n",
            "\n",
            "print(review)\n",
            "print(summary)\n",
            "review_tokenized = tokenizer(review, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_review_len)\n",
            "summary_tokenized = tokenizer(summary, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_summary_len)\n",
            "\n",
            "print(review_tokenized)\n",
            "print(summary_tokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Review:  What is to go wrong with a gift card. As long as it enters into a person's account as a credit it is just what you paid for.\n",
                  "Summary:  gift card\n",
                  "Rating: 5\n"
               ]
            }
         ],
         "source": [
            "# test the dataset\n",
            "dataset = ReviewDataset(df, t, max_review_len = max_review_len, max_summary_len = max_summary_len, lower_case = False)\n",
            "\n",
            "data_idx = 45\n",
            "\n",
            "# decode\n",
            "print(f\"Review: {ReviewDataset.detokenize(dataset, dataset[data_idx][0])}\")\n",
            "print(f\"Summary: {ReviewDataset.detokenize(dataset, dataset[data_idx][1])}\")\n",
            "print(f\"Rating: {int(dataset[data_idx][2])}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "' # Initialize the tokenizer and model\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\nmodel = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\")\\n\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Define the text you want to embed\\ntext = \"Hello, world!\"\\n\\n# Encode the text using the GPT-2 model\\nembedding, _ = model(tokenizer(text))\\n\\n\\n# Print the shape of the resulting embedding\\n# print(embedding.shape)  # (1, 13, 768) '"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"\"\" # Initialize the tokenizer and model\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "model = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\")\n",
            "\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "\n",
            "# Define the text you want to embed\n",
            "text = \"Hello, world!\"\n",
            "\n",
            "# Encode the text using the GPT-2 model\n",
            "embedding, _ = model(tokenizer(text))\n",
            "\n",
            "\n",
            "# Print the shape of the resulting embedding\n",
            "# print(embedding.shape)  # (1, 13, 768) \"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Model\n",
            "uses context aware word embedding\n",
            "multi-task network\n",
            "\n",
            "Input: takes in a review string\n",
            "Task 1: output a summary string of the input review with a max length defined by the dataset\n",
            "Task 2: output a rating of the input review as a float 0-1\n",
            "\n",
            "Use an encoder decoder setup with one decoder for each task\n",
            "\"\"\"\n",
            "\n",
            "class EncoderRNN(nn.Module):\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        super(EncoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "\n",
            "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
            "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
            "\n",
            "    def forward(self, input, hidden):\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        output = embedded\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "        return output, hidden\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)\n",
            "\n",
            "\n",
            "class AttnDecoderRNN(nn.Module):\n",
            "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
            "        super(AttnDecoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "        self.output_size = output_size\n",
            "        self.dropout_p = dropout_p\n",
            "        self.max_length = max_length\n",
            "\n",
            "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
            "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
            "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
            "        self.dropout = nn.Dropout(self.dropout_p)\n",
            "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
            "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
            "\n",
            "    def forward(self, input, hidden, encoder_outputs):\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        embedded = self.dropout(embedded)\n",
            "\n",
            "        attn_weights = nn.softmax(\n",
            "            self.attn(th.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
            "        attn_applied = th.bmm(attn_weights.unsqueeze(0),\n",
            "                                 encoder_outputs.unsqueeze(0))\n",
            "\n",
            "        output = th.cat((embedded[0], attn_applied[0]), 1)\n",
            "        output = self.attn_combine(output).unsqueeze(0)\n",
            "\n",
            "        output = nn.relu(output)\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "\n",
            "        output = nn.log_softmax(self.out(output[0]), dim=1)\n",
            "        return output, hidden, attn_weights\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                  "Input length of input_ids is 11, but `max_length` is set to 11. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': [1212, 318, 262, 1336, 2420, 326, 345, 765, 284, 35743, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
                  "11\n"
               ]
            },
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'index_select'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [54], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(encoded_prompt[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(inputs[\u001b[39m0\u001b[39m]))\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     22\u001b[0m     inputs,\n\u001b[1;32m     23\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(inputs[\u001b[39m0\u001b[39;49m]) ,  \u001b[39m# Half the length of the encoded input text\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoded_prompt[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOutput: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Print the generated summary\u001b[39;00m\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:1535\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1526\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1527\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1532\u001b[0m )\n\u001b[1;32m   1534\u001b[0m \u001b[39m# 11. expand input_ids with `num_return_sequences` additional sequences per batch\u001b[39;00m\n\u001b[0;32m-> 1535\u001b[0m input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expand_inputs_for_generation(\n\u001b[1;32m   1536\u001b[0m     input_ids,\n\u001b[1;32m   1537\u001b[0m     expand_size\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m   1538\u001b[0m     is_encoder_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mis_encoder_decoder,\n\u001b[1;32m   1539\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1542\u001b[0m \u001b[39m# 12. run sample\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m   1544\u001b[0m     input_ids,\n\u001b[1;32m   1545\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1554\u001b[0m )\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:648\u001b[0m, in \u001b[0;36mGenerationMixin._expand_inputs_for_generation\u001b[0;34m(input_ids, expand_size, is_encoder_decoder, attention_mask, encoder_outputs, **model_kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m token_type_ids\u001b[39m.\u001b[39mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39;49mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m is_encoder_decoder:\n\u001b[1;32m    651\u001b[0m     \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'index_select'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "\n",
            "#from pytorch_transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "import torch\n",
            "\n",
            "# Set the device\n",
            "device = \"cpu\"\n",
            "\n",
            "# Load the GPT-2 model and tokenizer\n",
            "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "model = model.to(device)\n",
            "\n",
            "# Generate a summary\n",
            "#prompt = \"Airbags are safety devices that are installed in vehicles to protect passengers in the event of a collision. When a collision occurs, sensors detect the impact and deploy the airbag, which inflates quickly to cushion the passengers and prevent them from being thrown forward or to the side. Airbags are typically located in the steering wheel and dashboard for the driver, and in the doors and roof pillars for the passengers. They are designed to deploy in a specific sequence to maximize the protection they provide. Modern airbags use advanced sensors and algorithms to tailor their deployment to the specific type and severity of the collision.\"\n",
            "prompt = \"This is the full text that you want to summarize.\"\n",
            "encoded_prompt = tokenizer(prompt)\n",
            "print(encoded_prompt)\n",
            "inputs = torch.tensor(encoded_prompt[\"input_ids\"]).unsqueeze(0).to(device)\n",
            "\n",
            "outputs = model.generate(\n",
            "    inputs,\n",
            "    max_length=len(inputs) // 2,  # Half the length of the encoded input text\n",
            "    temperature=0.5,\n",
            "    top_k=50,\n",
            "    top_p=0.9,\n",
            "    repetition_penalty=1.0,\n",
            "    do_sample=True,\n",
            "    num_return_sequences=1,\n",
            "    attention_mask=encoded_prompt[\"attention_mask\"],\n",
            ")\n",
            "print(\"Output: \")\n",
            "# Print the generated summary\n",
            "print(tokenizer.decode(outputs[0]))\n",
            "print(f\"The origianl text is {len(encoded_prompt)} tokens long, and the generated summary is {len(outputs[0])} tokens long.\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'ne'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_text)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Set the attention mask and pad token id\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m attention_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49mne(tokenizer\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     15\u001b[0m pad_token_id \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mpad_token_id\n\u001b[1;32m     17\u001b[0m \u001b[39m# Generate a response from the model\u001b[39;00m\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ne'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
            "\n",
            "# Load the GPT-2 tokenizer\n",
            "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
            "\n",
            "# Load the GPT-2 model\n",
            "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
            "\n",
            "# Encode a text input\n",
            "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
            "input_ids = tokenizer.encode(input_text)\n",
            "\n",
            "# Set the attention mask and pad token id\n",
            "attention_mask = input_ids.(tokenizer.pad_token_id).long()\n",
            "pad_token_id = tokenizer.pad_token_id\n",
            "\n",
            "# Generate a response from the model\n",
            "outputs = model.generate(\n",
            "    input_ids=input_ids,\n",
            "    attention_mask=attention_mask,\n",
            "    pad_token_id=pad_token_id\n",
            ")\n",
            "\n",
            "# Print the encoded text\n",
            "print(outputs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Dataset preparation\n",
            "Use the ReviewDataset to create a DataLoader\n",
            "Splitting the train, validation, and test sets\n",
            "\"\"\"\n",
            "# initialise the dataset\n",
            "dataset = ReviewDataset(df)\n",
            "dataset_size = len(dataset)\n",
            "\n",
            "# shrink dataset for testing\n",
            "dataset_size = 500\n",
            "dataset = th.utils.data.Subset(dataset, range(dataset_size))\n",
            "\n",
            "# split the dataset\n",
            "train_size = int(0.8 * dataset_size)\n",
            "val_size = int(0.1 * dataset_size)\n",
            "test_size = dataset_size - train_size - val_size\n",
            "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
            "\n",
            "# create the dataloaders\n",
            "batch_size = 32\n",
            "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
            "val_loader = th.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
            "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([32, 18152]) torch.Size([32]) torch.Size([32, 151])\n"
               ]
            }
         ],
         "source": [
            "# test the dataloader\n",
            "train_loader_iter = iter(train_loader)\n",
            "x, y, z = next(train_loader_iter)\n",
            "print(x.shape, y.shape, z.shape)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Training\n",
            "\"\"\"\n",
            "\"\"\" # initialise the model\n",
            "# take into account if it is a subset of the dataset\n",
            "model = Summariser(dataset.dataset.vocab_size, 256, max_review_len, max_summary_len)\n",
            "model = model.to(device)\n",
            "\n",
            "# define the loss functions\n",
            "loss_fn1 = th.nn.CrossEntropyLoss()\n",
            "loss_fn2 = th.nn.BCELoss()\n",
            "\n",
            "# define the optimiser\n",
            "optimiser = th.optim.Adam(model.parameters(), lr=0.001)\n",
            "\n",
            "# define the number of epochs\n",
            "epochs = 10\n",
            "\n",
            "# train the model\n",
            "for epoch in range(epochs):\n",
            "    for review, rating, summary in train_loader:\n",
            "        # zero the gradients\n",
            "        optimiser.zero_grad()\n",
            "\n",
            "        # forward pass\n",
            "        y_pred1, y_pred2 = model(review)\n",
            "\n",
            "        # calculate the loss\n",
            "        loss1 = loss_fn1(y_pred1, summary)\n",
            "        loss2 = loss_fn2(y_pred2, rating.unsqueeze(1).float())\n",
            "        loss = loss1 + loss2\n",
            "\n",
            "        # backward pass\n",
            "        loss.backward()\n",
            "\n",
            "        # update the weights\n",
            "        optimiser.step()\n",
            "\n",
            "    # print the loss\n",
            "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}') \"\"\"\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.8 ('deep-learning')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.8"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "c97f19f1a61f7391961f30397493e1a2688eb0342e378cc602641384d76195b8"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
