{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "import re\n",
    "\n",
    "device = th.device(\"mps\") if th.backends.mps.is_available() else th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(th.cuda.get_device_name(device))\n",
    "else:\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/\"\n",
    "\n",
    "# Dataset paths\n",
    "full_path = data_dir + \"full/\" # Use this for full dataset that contains all review matadata\n",
    "data_pruned = data_dir + \"pruned/\" # Only datasets with one number to the right side of it have a pruned version\n",
    "data_tokenized = data_dir + \"tokenized/\" # Only datasets with two numbers to the right side of it have a tokenized version\n",
    "\n",
    "full = \"All_Amazon_Review_5\" # 80 GB\n",
    "arts = \"Arts_Crafts_and_Sewing\" # 518 MB / 629 MB / 1.18 GB\n",
    "video = \"Amazon_Instant_Video_5\" # 28 MB\n",
    "\n",
    "# Pruned dataset paths\n",
    "\n",
    "# Read data with pandas\n",
    "#df = pd.read_json(data_pruned + arts + \".json\", lines=True)\n",
    "# Read csv with polars\n",
    "#df = pl.read_csv(data_pruned + arts + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' df = df.dropna(subset=[\"reviewtext\", \"summary\", \"overall\"])\\n\\n# Write reviewtext, summary or overall to csv\\ndf.to_csv(data_pruned + arts + \".csv\", index=False)\\n# Write reviewtext, summary or overall to json\\n#df[[\"reviewtext\", \"summary\", \"overall\"]].to_json(\"Pruned_Arts_Crafts_and_Sewing.json\", orient=\"records\", lines=True) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Prune a dataframe to only contain the columns we need \"\"\"\n",
    "# Drop all rows without a reviewtext or summary\n",
    "\"\"\" df = df.dropna(subset=[\"reviewtext\", \"summary\", \"overall\"])\n",
    "\n",
    "# Write reviewtext, summary or overall to csv\n",
    "df.to_csv(data_pruned + arts + \".csv\", index=False)\n",
    "# Write reviewtext, summary or overall to json\n",
    "#df[[\"reviewtext\", \"summary\", \"overall\"]].to_json(\"Pruned_Arts_Crafts_and_Sewing.json\", orient=\"records\", lines=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Tokenize reviewtext\\ndf[\"reviewtext\"] = df[\"reviewtext\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\\n\\n# Tokenize summary\\ndf[\"summary\"] = df[\"summary\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\\n\\n# Writing the tokenized data to csv\\ndf.to_csv(data_tokenized + arts + \".csv\", index=False) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize reviewtext and summary\n",
    "\"\"\" tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize reviewtext\n",
    "df[\"reviewtext\"] = df[\"reviewtext\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# Tokenize summary\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# Writing the tokenized data to csv\n",
    "df.to_csv(data_tokenized + arts + \".csv\", index=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5, 3)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "reviewtext\n",
       "</th>\n",
       "<th>\n",
       "summary\n",
       "</th>\n",
       "<th>\n",
       "overall\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i8\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;[40, 1053, 110...\n",
       "</td>\n",
       "<td>\n",
       "&quot;[32, 220, 370,...\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;[35284, 306, 3...\n",
       "</td>\n",
       "<td>\n",
       "&quot;[35284]&quot;\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;[23205, 340]&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;[20029, 10271]...\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;[10248, 3224, ...\n",
       "</td>\n",
       "<td>\n",
       "&quot;[10248, 20984,...\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;[32, 308, 1031...\n",
       "</td>\n",
       "<td>\n",
       "&quot;[36716, 306, 1...\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────────┬─────────────────────────────────────┬─────────┐\n",
       "│ reviewtext                          ┆ summary                             ┆ overall │\n",
       "│ ---                                 ┆ ---                                 ┆ ---     │\n",
       "│ str                                 ┆ str                                 ┆ i8      │\n",
       "╞═════════════════════════════════════╪═════════════════════════════════════╪═════════╡\n",
       "│ [40, 1053, 1100, 428, 1492, 1541... ┆ [32, 220, 370, 1340, 14418, 4647... ┆ 5       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ [35284, 306, 3194, 11678, 13]       ┆ [35284]                             ┆ 5       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ [23205, 340]                        ┆ [20029, 10271]                      ┆ 5       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ [10248, 3224, 41577, 4941, 284, ... ┆ [10248, 20984, 287, 27114, 5061]    ┆ 5       │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ [32, 308, 1031, 1131, 3912, 2809... ┆ [36716, 306, 1598, 11, 9321]        ┆ 5       │\n",
       "└─────────────────────────────────────┴─────────────────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tokenized data\n",
    "df = pl.read_csv(data_tokenized + arts + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Int8})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[32,', '220,', '370,', '1340,', '14418,', '46476,', '39633]']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '['",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m#df['summary'][1616449]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m# Detokenize reviewtext and summary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mreviewtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mreviewtext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: tokenizer\u001b[39m.\u001b[39;49mdecode(x))\n\u001b[1;32m     10\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tokenizer\u001b[39m.\u001b[39mdecode(x))\n\u001b[1;32m     12\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/polars/internals/series/series.py:3450\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, return_dtype, skip_nulls)\u001b[0m\n\u001b[1;32m   3448\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3449\u001b[0m     pl_return_dtype \u001b[39m=\u001b[39m py_type_to_dtype(return_dtype)\n\u001b[0;32m-> 3450\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_s(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_s\u001b[39m.\u001b[39;49mapply_lambda(func, pl_return_dtype, skip_nulls))\n",
      "Cell \u001b[0;32mIn [21], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m#df['summary'][1616449]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m# Detokenize reviewtext and summary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mreviewtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mreviewtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tokenizer\u001b[39m.\u001b[39;49mdecode(x))\n\u001b[1;32m     10\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tokenizer\u001b[39m.\u001b[39mdecode(x))\n\u001b[1;32m     12\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3436\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[39m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3434\u001b[0m token_ids \u001b[39m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3436\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode(\n\u001b[1;32m   3437\u001b[0m     token_ids\u001b[39m=\u001b[39;49mtoken_ids,\n\u001b[1;32m   3438\u001b[0m     skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens,\n\u001b[1;32m   3439\u001b[0m     clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m   3440\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/tokenization_utils.py:931\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode\u001b[39m(\n\u001b[1;32m    922\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    923\u001b[0m     token_ids: List[\u001b[39mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    928\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode_use_source_tokenizer \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39muse_source_tokenizer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 931\u001b[0m     filtered_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_ids_to_tokens(token_ids, skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens)\n\u001b[1;32m    933\u001b[0m     \u001b[39m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    934\u001b[0m     \u001b[39m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[39m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     sub_texts \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/tokenization_utils.py:906\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    904\u001b[0m tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    905\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m--> 906\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index)\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m skip_special_tokens \u001b[39mand\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_ids:\n\u001b[1;32m    908\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '['"
     ]
    }
   ],
   "source": [
    "print(df['summary'][0].split())\n",
    "\n",
    "np.argmax(df['summary'].apply(str.split).apply(len))\n",
    "#df['summary'][1616449]\n",
    "\n",
    "# Detokenize reviewtext and summary\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "df[\"reviewtext\"] = df[\"reviewtext\"].apply(lambda x: tokenizer.decode(x))\n",
    "df[\"summary\"] = df[\"summary\"].apply(lambda x: tokenizer.decode(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Series.max() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Lower case all strings\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#df.columns = map(str.lower, df.columns)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[39m# Find max length of review text with numpy\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m max_review_len \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmax(df[\u001b[39m'\u001b[39;49m\u001b[39mreviewtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlen\u001b[39;49m))\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMax length of review text: \u001b[39m\u001b[39m\"\u001b[39m, max_review_len)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Find max length of summary with numpy\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2793\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2678\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2679\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2680\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2793\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2794\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Series.max() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "# Lower case all strings\n",
    "#df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Keep only the review text, rating, and summary\n",
    "#df = df[['reviewtext', 'overall', 'summary']]\n",
    "\n",
    "# Find max length of review text with numpy\n",
    "max_review_len = np.max(df['reviewtext'].apply(len))\n",
    "print(\"\\nMax length of review text: \", max_review_len)\n",
    "# Find max length of summary with numpy\n",
    "max_summary_len = np.max((df['summary'].apply(len)))\n",
    "print(\"Max length of summary: \", max_summary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m s_counts, s_bins \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhistogram(df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m), bins\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      7\u001b[0m r_counts \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(r_counts[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(s_bins)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(s_counts)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a distribution of review lengths with log scale\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "r_counts, r_bins = np.histogram(df['reviewtext'].apply(len), bins=100)\n",
    "s_counts, s_bins = np.histogram(df['summary'].apply(len), bins=100)\n",
    "\n",
    "r_counts = df['summary'].apply(len).value_counts()\n",
    "print(r_counts)\n",
    "\n",
    "print(s_bins)\n",
    "print(s_counts)\n",
    "\n",
    "print(len(r_counts), len(r_bins), len(s_counts), len(s_bins))\n",
    "\n",
    "ax[0].hist(df['reviewtext'].apply(len), bins=100, log=True)\n",
    "ax[0].set_title(\"Distribution of review lengths\")\n",
    "ax[0].set_xlabel(\"Review length\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "\n",
    "ax[1].hist(df['summary'].apply(len), bins=100, log=True)\n",
    "ax[1].set_title(\"Distribution of summary lengths\")\n",
    "ax[1].set_xlabel(\"summary length\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset from pandas dataframe\n",
    "# defines a voacbulary of words and converts the review text to a list of indices\n",
    "# beware of symbols like ., !, ? etc.\n",
    "# pad the review text and summary to max_review_len and max_summary_len respectively\n",
    "\n",
    "class ReviewDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.df.iloc[idx, 0].split()\n",
    "        review = [self.vocab2idx[word] for word in review]\n",
    "        review = th.tensor(review, dtype=th.long)\n",
    "        review = th.nn.functional.pad(review, (0, max_review_len - len(review)))\n",
    "        rating = self.df.iloc[idx, 1]\n",
    "        rating = th.tensor(rating, dtype=th.long)\n",
    "        summary = self.df.iloc[idx, 2].split()\n",
    "        summary = [self.vocab2idx[word] for word in summary]\n",
    "        summary = th.tensor(summary, dtype=th.long)\n",
    "        summary = th.nn.functional.pad(summary, (0, max_summary_len - len(summary)))\n",
    "\n",
    "        # move tensors to device\n",
    "        review = review.to(device)\n",
    "        rating = rating.to(device)\n",
    "        summary = summary.to(device)\n",
    "        \n",
    "        return review, rating, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset from pandas dataframe\n",
    "# defines a voacbulary of words and converts the review text to a list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# test the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataset \u001b[39m=\u001b[39m ReviewDataset(df)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(dataset[\u001b[39m0\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn [7], line 37\u001b[0m, in \u001b[0;36mReviewDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m review \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(review, (\u001b[39m0\u001b[39m, max_review_len \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(review)))\n\u001b[1;32m     36\u001b[0m rating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m rating \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mtensor(rating, dtype\u001b[39m=\u001b[39;49mth\u001b[39m.\u001b[39;49mlong)\n\u001b[1;32m     38\u001b[0m summary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39miloc[idx, \u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit()\n\u001b[1;32m     39\u001b[0m summary \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab2idx[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m summary]\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "# test the dataset\n",
    "dataset = ReviewDataset(df)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model\n",
    "uses context aware word embedding\n",
    "multi-task network\n",
    "\n",
    "Input: takes in a review string\n",
    "Task 1: output a summary string of the input review with a max length defined by the dataset\n",
    "Task 2: output a rating of the input review as a float 0-1\n",
    "\n",
    "Use an encoder decoder setup with one decoder for each task\n",
    "\"\"\"\n",
    "class Summariser(th.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_review_len, max_summary_len):\n",
    "        super(Summariser, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_review_len = max_review_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "        self.embedding = th.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.decoder1 = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, batch_first=True)\n",
    "        self.decoder2 = th.nn.LSTM(embedding_dim, embedding_dim, num_layers=2, batch_first=True)\n",
    "        self.linear1 = th.nn.Linear(embedding_dim, vocab_size)\n",
    "        self.linear2 = th.nn.Linear(embedding_dim, 1)\n",
    "        self.softmax = th.nn.Softmax(dim=2)\n",
    "        self.sigmoid = th.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.encoder(x)\n",
    "        x1, _ = self.decoder1(x)\n",
    "        x2, _ = self.decoder2(x)\n",
    "        x1 = self.linear1(x1)\n",
    "        x1 = self.softmax(x1)\n",
    "        x2 = self.linear2(x2)\n",
    "        x2 = self.sigmoid(x2)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset preparation\n",
    "Use the ReviewDataset to create a DataLoader\n",
    "Splitting the train, validation, and test sets\n",
    "\"\"\"\n",
    "# initialise the dataset\n",
    "dataset = ReviewDataset(df)\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "# shrink dataset for testing\n",
    "dataset_size = 500\n",
    "dataset = th.utils.data.Subset(dataset, range(dataset_size))\n",
    "\n",
    "# split the dataset\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# create the dataloaders\n",
    "batch_size = 32\n",
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = th.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 18152]) torch.Size([32]) torch.Size([32, 151])\n"
     ]
    }
   ],
   "source": [
    "# test the dataloader\n",
    "train_loader_iter = iter(train_loader)\n",
    "x, y, z = next(train_loader_iter)\n",
    "print(x.shape, y.shape, z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "\"\"\" # initialise the model\n",
    "# take into account if it is a subset of the dataset\n",
    "model = Summariser(dataset.dataset.vocab_size, 256, max_review_len, max_summary_len)\n",
    "model = model.to(device)\n",
    "\n",
    "# define the loss functions\n",
    "loss_fn1 = th.nn.CrossEntropyLoss()\n",
    "loss_fn2 = th.nn.BCELoss()\n",
    "\n",
    "# define the optimiser\n",
    "optimiser = th.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# train the model\n",
    "for epoch in range(epochs):\n",
    "    for review, rating, summary in train_loader:\n",
    "        # zero the gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        y_pred1, y_pred2 = model(review)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss1 = loss_fn1(y_pred1, summary)\n",
    "        loss2 = loss_fn2(y_pred2, rating.unsqueeze(1).float())\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimiser.step()\n",
    "\n",
    "    # print the loss\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}') \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch1.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74ce01c583b9da8e861aa1ee054dcef8ec2fe05bc1a1578aa65fd6e69a36df1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
