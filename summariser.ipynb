{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "NVIDIA GeForce RTX 2070 SUPER\n"
               ]
            }
         ],
         "source": [
            "# Math and data\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import polars as pl\n",
            "# Neural network frameworks\n",
            "import torch as th\n",
            "from torch import nn\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config, GPT2LMHeadModel, GPT2DoubleHeadsModel\n",
            "# Utilities\n",
            "import re\n",
            "from enum import Enum\n",
            "import contractions as ct\n",
            "import utility as ru\n",
            "# Plotting\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Pytorch device\n",
            "device = th.device(\"mps\") if th.backends.mps.is_available() else th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
            "if device.type == \"cuda\":\n",
            "    print(th.cuda.get_device_name(device))\n",
            "else:\n",
            "    print(device)\n",
            "\n",
            "device = th.device(\"cpu\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Max token length of review text:  553\n",
                  "Max token length of summary:  27\n"
               ]
            }
         ],
         "source": [
            "# Use simple GPT2 tokenizer for counting tokens\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "\n",
            "# Load dataset -> Prune dataset -> Tokenize dataset\n",
            "df = ru.load_dataset(ru.Paths.gift, ru.DatasetType.ORIGINAL)\n",
            "df = ru.prune(df)\n",
            "ru.save_dataset(df, ru.Paths.gift, ru.DatasetType.PRUNED)\n",
            "df = ru.tokenize(df, tokenizer)\n",
            "\n",
            "# Find max token length of review text with numpy\n",
            "max_review_len = np.max(list(df['reviewText'].apply(list).apply(len)))\n",
            "print(\"\\nMax token length of review text: \", max_review_len)\n",
            "# Find max token length of summary with numpy\n",
            "max_summary_len = np.max((list(df['summary'].apply(list).apply(len))))\n",
            "print(\"Max token length of summary: \", max_summary_len)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# torch dataset from pandas dataframe\n",
            "# defines a voacbulary of words and converts the review text to a list of indices\n",
            "# beware of symbols like ., !, ? etc.\n",
            "# pad the review text and summary to max_review_len and max_summary_len respectively\n",
            "\n",
            "\"\"\"\n",
            "ReviewDataset pytorch dataset interface\n",
            "- expects a polars dataframe with columns reviewText, summary, overall\n",
            "- expects it in the DatasetType.PRUNED format\n",
            "- expects a GPT2Tokenizer\n",
            "\"\"\"\n",
            "class ReviewDataset(Dataset):\n",
            "    def __init__(self, df: pl.DataFrame, tokenizer: GPT2Tokenizer, dataset_type = ru.DatasetType.PRUNED, max_review_len = 2000, max_summary_len = 200, lower_case = True, device = \"cpu\"):\n",
            "        self.df = ru.load_dataset(ru.Paths.gift, dataset_type)\n",
            "        self.dataset_type = dataset_type\n",
            "        self.max_review_len = max_review_len\n",
            "        self.max_summary_len = max_summary_len\n",
            "        self.tokenizer = tokenizer\n",
            "        self.lower_case = lower_case\n",
            "        self.device = device\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.df)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        review = self.df[\"reviewText\"][idx]\n",
            "        summary = self.df[\"summary\"][idx]\n",
            "        rating = th.tensor(self.df[\"overall\"][idx])\n",
            "\n",
            "        # Tokenize the review and summary strings\n",
            "        review = self.tokenizer.encode(review, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_review_len, return_tensors = \"pt\").squeeze()\n",
            "        summary = self.tokenizer.encode(summary, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_summary_len, return_tensors = \"pt\").squeeze()\n",
            "\n",
            "        # move tensors to device\n",
            "        review = review.to(self.device)\n",
            "        summary = summary.to(self.device)\n",
            "        rating = rating.to(self.device)\n",
            "        \n",
            "        return review, summary, rating\n",
            "    \n",
            "    def detokenize(self, x: th.Tensor):\n",
            "        return self.tokenizer.decode(x, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Review:  what is to go wrong with a gift card. as long as it enters into a person's account as a credit it is just what you paid for.\n",
                  "Summary:  gift card\n",
                  "Rating: 1\n",
                  "MAX_LENGTH: 50257\n"
               ]
            }
         ],
         "source": [
            "# Test the dataset\n",
            "# Setup\n",
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=\"<|pad|>\", bos_token=\"<|bos|>\", eos_token=\"<|eos|>\", unk_token=\"<|unk|>\", add_bos_token=False, add_prefix_space=True, trim_offsets=True)\n",
            "# Create the dataset\n",
            "dataset = ReviewDataset(ru.Paths.gift, t, max_review_len = max_review_len, max_summary_len = max_summary_len, lower_case = False, device=device)\n",
            "\n",
            "data_idx = 45\n",
            "\n",
            "# decode\n",
            "print(f\"Review: {ReviewDataset.detokenize(dataset, dataset[data_idx][0])}\")\n",
            "print(f\"Summary: {ReviewDataset.detokenize(dataset, dataset[data_idx][1])}\")\n",
            "print(f\"Rating: {int(dataset[data_idx][2])}\")\n",
            "\n",
            "# max length is the max index of the vocabulary\n",
            "MAX_LENGTH = t.vocab_size\n",
            "print(f\"MAX_LENGTH: {MAX_LENGTH}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Model\n",
            "\"\"\"\n",
            "\n",
            "class EncoderRNN(nn.Module):\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        super(EncoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "\n",
            "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
            "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
            "\n",
            "    def forward(self, input, hidden):\n",
            "        # assert input.get_device() == device\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        output = embedded\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "        return output, hidden\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)\n",
            "\n",
            "\n",
            "class AttnDecoderRNN(nn.Module):\n",
            "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
            "        super(AttnDecoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "        self.output_size = output_size\n",
            "        self.dropout_p = dropout_p\n",
            "        self.max_length = max_length\n",
            "\n",
            "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
            "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
            "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
            "        self.dropout = nn.Dropout(self.dropout_p)\n",
            "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
            "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
            "\n",
            "    def forward(self, input, hidden, encoder_outputs):\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        embedded = self.dropout(embedded)\n",
            "\n",
            "        attn_weights = nn.softmax(\n",
            "            self.attn(th.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
            "        attn_applied = th.bmm(attn_weights.unsqueeze(0),\n",
            "                                 encoder_outputs.unsqueeze(0))\n",
            "\n",
            "        output = th.cat((embedded[0], attn_applied[0]), 1)\n",
            "        output = self.attn_combine(output).unsqueeze(0)\n",
            "\n",
            "        output = nn.relu(output)\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "\n",
            "        output = nn.log_softmax(self.out(output[0]), dim=1)\n",
            "        return output, hidden, attn_weights\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "cpu\n",
                  "-1\n"
               ]
            }
         ],
         "source": [
            "print(device.type)\n",
            "print(th.tensor([1,2,3]).to(device).get_device())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "ename": "IndexError",
               "evalue": "index out of range in self",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                  "Cell \u001b[1;32mIn [7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Run the encoder\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m input_tensor:\n\u001b[1;32m---> 21\u001b[0m     encoder_output, encoder_hidden \u001b[39m=\u001b[39m encoder1(token, encoder_hidden)\n\u001b[0;32m     22\u001b[0m     encoder_outputs[token] \u001b[39m=\u001b[39m encoder_output[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncoder output shape: \u001b[39m\u001b[39m{\u001b[39;00mencoder_outputs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                  "Cell \u001b[1;32mIn [5], line 15\u001b[0m, in \u001b[0;36mEncoderRNN.forward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, hidden):\n\u001b[0;32m     14\u001b[0m     \u001b[39m# assert input.get_device() == device\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(\u001b[39minput\u001b[39;49m)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m     output \u001b[39m=\u001b[39m embedded\n\u001b[0;32m     17\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(output, hidden)\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
                  "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
               ]
            }
         ],
         "source": [
            "# Test the model with a single forward pass\n",
            "hidden_size = 256\n",
            "encoder1 = EncoderRNN(t.vocab_size, hidden_size).to(device)\n",
            "decoder1 = AttnDecoderRNN(hidden_size, t.vocab_size, dropout_p=0.1).to(device)\n",
            "\n",
            "# dl = DataLoader(dataset)\n",
            "# dl_it = iter(dl)\n",
            "\n",
            "# Take input from the dataset\n",
            "input_tensor, target_tensor, rating_tensor = dataset[data_idx]\n",
            "# print(input_tensor.get_device())\n",
            "\n",
            "# Create the encoder hidden state\n",
            "encoder_hidden = encoder1.initHidden()\n",
            "\n",
            "# Initialise the encoder output\n",
            "encoder_outputs = th.zeros(MAX_LENGTH, encoder1.hidden_size, device=device)\n",
            "\n",
            "# Run the encoder\n",
            "for token in input_tensor:\n",
            "    encoder_output, encoder_hidden = encoder1(token, encoder_hidden)\n",
            "    encoder_outputs[token] = encoder_output[0, 0]\n",
            "\n",
            "print(f\"Encoder output shape: {encoder_outputs.shape}\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.8 64-bit (microsoft store)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.8"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "69323fde9fc4d20886c37f6bdc4a05b4e3b82913212d2329f781a907e0bb44ca"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
