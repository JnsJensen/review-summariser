{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "NVIDIA GeForce RTX 2070 SUPER\n"
               ]
            }
         ],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import polars as pl\n",
            "import matplotlib.pyplot as plt\n",
            "import torch as th\n",
            "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config, GPT2LMHeadModel, GPT2DoubleHeadsModel\n",
            "import re\n",
            "from enum import Enum\n",
            "import contractions as ct\n",
            "from torch import nn\n",
            "\n",
            "device = th.device(\"mps\") if th.backends.mps.is_available() else th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
            "\n",
            "if device.type == \"cuda\":\n",
            "    print(th.cuda.get_device_name(device))\n",
            "else:\n",
            "    print(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_dir = \"datasets/\"\n",
            "\n",
            "# Dataset paths\n",
            "data_original = data_dir + \"full/\" # Use this for full dataset that contains all review matadata\n",
            "data_pruned = data_dir + \"pruned/\" # Only datasets with one number to the right side of it have a pruned version\n",
            "data_tokenized = data_dir + \"tokenized/\" # Only datasets with two numbers to the right side of it have a tokenized version\n",
            "\n",
            "full = \"All_Amazon_Review_5\" # 80 GB\n",
            "arts = \"Arts_Crafts_and_Sewing\" # 518 MB / 629 MB / 1.18 GB\n",
            "video = \"Amazon_Instant_Video_5\" # 28 MB\n",
            "gift = \"Gift_Cards_5\" # 0.88 MB\n",
            "\n",
            "PAD_token = \"<|pad|>\"\n",
            "BOS_token = \"<|bos|>\"\n",
            "EOS_token = \"<|eos|>\"\n",
            "UNK_token = \"<|unk|>\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "DatasetType enum\n",
            "- ORIGINAL: The original json dataset\n",
            "- PRUNED: The pruned csv dataset\n",
            "- TOKENIZED: The tokenized csv dataset\n",
            "\"\"\"\n",
            "class DatasetType(Enum):\n",
            "    ORIGINAL = 0\n",
            "    PRUNED = 1\n",
            "    TOKENIZED = 2\n",
            "\n",
            "listify = lambda x: x.split(\"|\")\n",
            "stringify = lambda x: \"|\".join(list(x.cast(pl.Utf8)))\n",
            "\n",
            "\"\"\"\n",
            "Normalizes strings by:\n",
            "- Removing double spaces\n",
            "- Converting to lower case\n",
            "- Expanding contractions\n",
            "\"\"\"\n",
            "def normalize_text(text: str) -> str:\n",
            "    return re.sub(r\"\\s+\", \" \", ct.fix(text.lower()))\n",
            "\n",
            "\"\"\"\n",
            "Normalizes the reviewText and summary columns of a dataframe by:\n",
            "- Using normalize_text on the 'reviewText' and 'summary' columns\n",
            "\"\"\"\n",
            "def normalize_text_df(df: pl.DataFrame) -> pl.DataFrame:\n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"reviewText\").apply(normalize_text),\n",
            "        pl.col(\"summary\").apply(normalize_text),\n",
            "        pl.exclude([\"reviewText\", \"summary\"])\n",
            "    ]).collect()\n",
            "    return df\n",
            "\n",
            "\"\"\"\n",
            "Prunes the dataset by:\n",
            "- Removing reviews with a summary of \"five stars\", \"four stars\", \"three stars\", \"two stars\", or \"one star\n",
            "- Normalizing the reviewText and summary columns by the use of normalize_text_df\n",
            "- Converting the overall column to a float between 0 and 1\n",
            "\"\"\"\n",
            "def prune(df: pd.DataFrame | pl.DataFrame) -> pl.DataFrame:\n",
            "    # list of unwanted summaries in lower case\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df = pl.DataFrame(df.dropna())\n",
            "    assert(isinstance(df, pl.DataFrame))\n",
            "\n",
            "    df = normalize_text_df(df)\n",
            "\n",
            "    df = df.filter(pl.col(\"summary\") != \"five stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"four stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"three stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"two stars\") \\\n",
            "           .filter(pl.col(\"summary\") != \"one star\")\n",
            "    \n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"overall\").apply(lambda x: int(x)/5),\n",
            "        pl.exclude([\"overall\"])\n",
            "    ]).collect()\n",
            "    return df.select([pl.col(\"reviewText\"), pl.col(\"summary\"), pl.col(\"overall\")])\n",
            "\n",
            "\"\"\"\n",
            "Writes a dataframe to a csv file\n",
            "- Distinguishes between polars and pandas dataframes\n",
            "\"\"\"\n",
            "def write_to_csv(df: pd.DataFrame | pl.DataFrame, path: str) -> None:\n",
            "    if isinstance(df, pd.DataFrame):\n",
            "        df.to_csv(path + \".csv\", index=False)\n",
            "    elif isinstance(df, pl.DataFrame):\n",
            "        df.write_csv(path + \".csv\")\n",
            "\n",
            "\"\"\"\n",
            "Tokenizes the reviewText and summary columns of a dataframe by:\n",
            "- Using the tokenizer to encode the 'reviewText' and 'summary' columns\n",
            "\"\"\"\n",
            "def tokenize(df: pl.DataFrame, tokenizer: GPT2Tokenizer) -> pl.DataFrame:\n",
            "    t = lambda x: tokenizer.encode(x, add_special_tokens=True)\n",
            "    df = df.lazy().select([\n",
            "        pl.col(\"reviewText\").apply(t),\n",
            "        pl.col(\"summary\").apply(t),\n",
            "        pl.exclude([\"reviewText\", \"summary\"])\n",
            "    ]).collect()\n",
            "    return df\n",
            "\n",
            "\"\"\"\n",
            "Loads a dataset from a csv file\n",
            "- Distinguishes between polars and pandas dataframes\n",
            "- Distinguishes between the original, pruned, and tokenized datasets\n",
            "\"\"\"\n",
            "def load_dataset(dataset: str, dataset_type: DatasetType, keep_cols = [\"reviewText\", \"summary\", \"overall\"]) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        # return pl.read_json(data_original + dataset + \".json\", json_lines=True).select([keep_cols])\n",
            "        return pd.read_json(data_original + dataset + \".json\", lines=True)[keep_cols]\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        return pl.read_csv(data_pruned + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Float32})\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = pl.read_csv(data_tokenized + dataset + \".csv\", dtypes={\"reviewtext\": pl.Utf8, \"summary\": pl.Utf8, \"overall\": pl.Float32})\n",
            "        \n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.col(\"summary\").apply(listify).cast(pl.List(pl.Int64)),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        return df\n",
            "\n",
            "\"\"\"\n",
            "Saves a dataset to a csv file\n",
            "- Distinguishes between the pruned and tokenized datasets\n",
            "\"\"\"\n",
            "def save_dataset(df: pl.DataFrame, dataset: str, dataset_type: DatasetType) -> None:\n",
            "    if dataset_type == DatasetType.PRUNED:\n",
            "        write_to_csv(df, data_pruned + dataset)\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        \n",
            "        df = df.lazy().select([\n",
            "            pl.col(\"reviewText\").apply(stringify),\n",
            "            pl.col(\"summary\").apply(stringify),\n",
            "            pl.exclude([\"reviewText\", \"summary\"])\n",
            "        ]).collect()\n",
            "        write_to_csv(df, data_tokenized + dataset)\n",
            "\n",
            "\"\"\"\n",
            "Preprocesses a dataset by:\n",
            "- Loading the dataset\n",
            "- Pruning the dataset\n",
            "- Tokenizing the dataset\n",
            "\"\"\"\n",
            "def preprocess(dataset: str, dataset_type: DatasetType, tokenizer, keep_cols = [\"reviewText\", \"summary\", \"overall\"], save_steps=True) -> pd.DataFrame | pl.DataFrame:\n",
            "    if dataset_type == DatasetType.ORIGINAL:\n",
            "        df = load_dataset(dataset, dataset_type, keep_cols)\n",
            "        df = prune(df)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.PRUNED)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.PRUNED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        df = tokenize(df, tokenizer)\n",
            "        if save_steps:\n",
            "            save_dataset(df, dataset, DatasetType.TOKENIZED)\n",
            "        return df\n",
            "    elif dataset_type == DatasetType.TOKENIZED:\n",
            "        df = load_dataset(dataset, dataset_type)\n",
            "        return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Prune and save\n",
            "df = load_dataset(gift, DatasetType.ORIGINAL)\n",
            "df = prune(df)\n",
            "save_dataset(df, gift, DatasetType.PRUNED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "not much to say, gift card is as good as cash!\n",
                  "gift card is as good as cash\n",
                  "1.0\n",
                  "shape: (5, 3)\n",
                  "┌────────────────────┬──────────────────────┬─────────┐\n",
                  "│ reviewText         ┆ summary              ┆ overall │\n",
                  "│ ---                ┆ ---                  ┆ ---     │\n",
                  "│ list[i64]          ┆ list[i64]            ┆ f32     │\n",
                  "╞════════════════════╪══════════════════════╪═════════╡\n",
                  "│ [5661, 373, ... 0] ┆ [7079, 540, 0]       ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [70, 2135]         ┆ [18223, 6979]        ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [37784, 922, 0]    ┆ [37784, 922, 0]      ┆ 1.0     │\n",
                  "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                  "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                  "└────────────────────┴──────────────────────┴─────────┘\n",
                  "70|2135|2657|329|616|4957\n"
               ]
            }
         ],
         "source": [
            "# Tokenize and save\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "print(df[\"reviewText\"][-1])\n",
            "print(df[\"summary\"][-1])\n",
            "print(df[\"overall\"][-1])\n",
            "\n",
            "df = tokenize(df, tokenizer)\n",
            "print(df.tail())\n",
            "\n",
            "print(\"|\".join(list(df[\"reviewText\"][0].cast(pl.Utf8))))\n",
            "save_dataset(df, gift, DatasetType.TOKENIZED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        white-space: pre;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-top: 0;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe td {\n",
                     "        padding-bottom: 0;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\" >\n",
                     "<small>shape: (5, 3)</small>\n",
                     "<thead>\n",
                     "<tr>\n",
                     "<th>\n",
                     "reviewText\n",
                     "</th>\n",
                     "<th>\n",
                     "summary\n",
                     "</th>\n",
                     "<th>\n",
                     "overall\n",
                     "</th>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "list[i64]\n",
                     "</td>\n",
                     "<td>\n",
                     "f32\n",
                     "</td>\n",
                     "</tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[5661, 373, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[7079, 540, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "1.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[1662, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "1.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[70, 2135]\n",
                     "</td>\n",
                     "<td>\n",
                     "[18223, 6979]\n",
                     "</td>\n",
                     "<td>\n",
                     "1.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[37784, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[37784, 922, 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "1.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "<tr>\n",
                     "<td>\n",
                     "[1662, 881, ... 0]\n",
                     "</td>\n",
                     "<td>\n",
                     "[70, 2135, ... 5003]\n",
                     "</td>\n",
                     "<td>\n",
                     "1.0\n",
                     "</td>\n",
                     "</tr>\n",
                     "</tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "shape: (5, 3)\n",
                     "┌────────────────────┬──────────────────────┬─────────┐\n",
                     "│ reviewText         ┆ summary              ┆ overall │\n",
                     "│ ---                ┆ ---                  ┆ ---     │\n",
                     "│ list[i64]          ┆ list[i64]            ┆ f32     │\n",
                     "╞════════════════════╪══════════════════════╪═════════╡\n",
                     "│ [5661, 373, ... 0] ┆ [7079, 540, 0]       ┆ 1.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [70, 2135]         ┆ [18223, 6979]        ┆ 1.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [37784, 922, 0]    ┆ [37784, 922, 0]      ┆ 1.0     │\n",
                     "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
                     "│ [1662, 881, ... 0] ┆ [70, 2135, ... 5003] ┆ 1.0     │\n",
                     "└────────────────────┴──────────────────────┴─────────┘"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Load the tokenized data\n",
            "df = load_dataset(gift, DatasetType.TOKENIZED)\n",
            "df.tail()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Max length of review text:  553\n",
                  "Max length of summary:  27\n"
               ]
            }
         ],
         "source": [
            "# df = load_dataset(arts, DatasetType.TOKENIZED)\n",
            "\n",
            "# Find max length of review text with numpy\n",
            "max_review_len = np.max(list(df['reviewText'].apply(list).apply(len)))\n",
            "print(\"\\nMax length of review text: \", max_review_len)\n",
            "# Find max length of summary with numpy\n",
            "max_summary_len = np.max((list(df['summary'].apply(list).apply(len))))\n",
            "print(\"Max length of summary: \", max_summary_len)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# df = preprocess(arts, DatasetType.ORIGINAL, tokenizer)\n",
            "\n",
            "# Plot a distribution of review lengths with log scale\n",
            "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
            "\n",
            "r_counts, r_bins = np.histogram(df[\"reviewText\"].apply(len), bins=100)\n",
            "s_counts, s_bins = np.histogram(df[\"summary\"].apply(len), bins=100)\n",
            "\n",
            "r_vcounts = df[\"reviewText\"].apply(len).value_counts()\n",
            "s_vcounts = df[\"summary\"].apply(len).value_counts()\n",
            "r_vbins = list(r_vcounts[\"reviewText\"])\n",
            "s_vbins = list(s_vcounts[\"summary\"])\n",
            "\n",
            "log_yscale = True\n",
            "\n",
            "ax[0].hist(df[\"reviewText\"].apply(len), bins=range(np.min(r_vbins), np.max(r_vbins)), log=log_yscale)\n",
            "ax[0].set_title(\"Distribution of review lengths\")\n",
            "ax[0].set_xlabel(\"Review length\")\n",
            "ax[0].set_ylabel(\"Frequency\")\n",
            "ax[0].grid()\n",
            "\n",
            "ax[1].hist(df[\"summary\"].apply(len), bins=range(np.min(s_vbins), np.max(s_vbins)), log=log_yscale)\n",
            "ax[1].set_title(\"Distribution of summary lengths\")\n",
            "ax[1].set_xlabel(\"summary length\")\n",
            "ax[1].set_ylabel(\"Frequency\")\n",
            "ax[1].grid()\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "382820\n",
                  "1345\n"
               ]
            }
         ],
         "source": [
            "print(pl.DataFrame.estimated_size(df))\n",
            "print(len(df))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': tensor([[ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259],\n",
                  "        [ 1312,   716,    13, 50259, 50259, 50259, 50259, 50259, 50259, 50259]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
                  "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
                  "[' i am.', ' i am.', ' i am.']\n"
               ]
            }
         ],
         "source": [
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=PAD_token, bos_token=BOS_token, eos_token=EOS_token, unk_token=UNK_token, add_bos_token=False, add_prefix_space=True, trim_offsets=True)\n",
            "# t.add_special_tokens({'pad_token': '<pad>'})\n",
            "# t.add_special_tokens({'bos_token': '<bos>'})\n",
            "# t.add_special_tokens({'eos_token': '<eos>'})\n",
            "\n",
            "sentences = [\n",
            "    \"I'm.\",\n",
            "    \"i'm.\",\n",
            "    \"I am.\"\n",
            "]\n",
            "\n",
            "sentences = [\n",
            "    \" \".join([\n",
            "        ct.fix(word)\n",
            "        for word in sentence.split()\n",
            "    ]).lower()\n",
            "    for sentence in sentences\n",
            "]\n",
            "\n",
            "# sentences = \"one sentence\"\n",
            "\n",
            "tokenized = t(sentences, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=10, return_tensors = \"pt\")\n",
            "print(tokenized)\n",
            "\n",
            "decoding = lambda x, t, **kwargs : t.decode(x, kwargs) if isinstance(x, list) or isinstance(x, tuple) else t.batch_decode(x[\"input_ids\"], kwargs)\n",
            "\n",
            "# detokenized = t.batch_decode(tokenized[\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "detokenized = decoding(tokenized, t, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
            "print(detokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# torch dataset from pandas dataframe\n",
            "# defines a voacbulary of words and converts the review text to a list of indices\n",
            "# beware of symbols like ., !, ? etc.\n",
            "# pad the review text and summary to max_review_len and max_summary_len respectively\n",
            "\n",
            "\"\"\"\n",
            "ReviewDataset pytorch dataset interface\n",
            "- expects a polars dataframe with columns reviewText, summary, overall\n",
            "- expects it in the DatasetType.PRUNED format\n",
            "- expects a GPT2Tokenizer\n",
            "\"\"\"\n",
            "class ReviewDataset(th.utils.data.Dataset):\n",
            "    def __init__(self, df: pl.DataFrame, tokenizer: GPT2Tokenizer, dataset_type = DatasetType.PRUNED, max_review_len = 2000, max_summary_len = 200, lower_case = True, device = \"cpu\"):\n",
            "        self.df = df\n",
            "        self.dataset_type = dataset_type\n",
            "        self.max_review_len = max_review_len\n",
            "        self.max_summary_len = max_summary_len\n",
            "        self.tokenizer = tokenizer\n",
            "        self.lower_case = lower_case\n",
            "        self.device = device\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.df)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        review = self.df[\"reviewText\"][idx]\n",
            "        summary = self.df[\"summary\"][idx]\n",
            "        rating = th.tensor(self.df[\"overall\"][idx])\n",
            "\n",
            "        # Tokenize the review and summary strings\n",
            "        review = self.tokenizer.encode(review, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_review_len, return_tensors = \"pt\").squeeze()\n",
            "        summary = self.tokenizer.encode(summary, add_special_tokens = True, padding = \"max_length\", truncation = True, max_length=self.max_summary_len, return_tensors = \"pt\").squeeze()\n",
            "\n",
            "        # move tensors to device\n",
            "        review = review.to(self.device)\n",
            "        summary = summary.to(self.device)\n",
            "        rating = rating.to(self.device)\n",
            "        \n",
            "        return review, summary, rating\n",
            "    \n",
            "    def detokenize(self, x: th.Tensor):\n",
            "        return self.tokenizer.decode(x, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            }
         ],
         "source": [
            "# test the ReviewDataset class\n",
            "t = GPT2Tokenizer.from_pretrained(\"gpt2\", pad_token=\"<|pad|>\", bos_token=\"<|bos|>\", eos_token=\"<|eos|>\", unk_token=\"<|unk|>\", add_bos_token=False, add_prefix_space=True, trim_offsets=True)\n",
            "idx = 45\n",
            "df = load_dataset(gift, DatasetType.PRUNED)\n",
            "dataset = ReviewDataset(df, t, max_review_len=max_review_len, max_summary_len=max_summary_len, device=device)\n",
            "# print(dataset[45])\n",
            "# test the detokenize method\n",
            "# print(dataset.detokenize(dataset[45][0]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [],
         "source": [
            "# df = load_dataset(gift, DatasetType.PRUNED)\n",
            "\n",
            "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "# tokenizer.add_special_tokens({\"pad_token\": PAD_token})\n",
            "# # tokenizer.add_special_tokens({\"eos_token\": \"<|eos|>\"})\n",
            "# # tokenizer.add_special_tokens({\"bos_token\": \"<|bos|>\"})\n",
            "\n",
            "# # I'm\n",
            "# # i'm\n",
            "# # I am\n",
            "\n",
            "# idx = 38\n",
            "\n",
            "# review = df[\"reviewText\"][idx]\n",
            "# review = ct.fix(review.lower())\n",
            "# summary = df[\"summary\"][idx]\n",
            "# summary = ct.fix(summary.lower())\n",
            "\n",
            "# print(review)\n",
            "# print(summary)\n",
            "# review_tokenized = tokenizer(review, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_review_len)\n",
            "# summary_tokenized = tokenizer(summary, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_summary_len)\n",
            "\n",
            "# print(review_tokenized)\n",
            "# print(summary_tokenized)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Review:  what is to go wrong with a gift card. as long as it enters into a person's account as a credit it is just what you paid for.\n",
                  "Summary:  gift card\n",
                  "Rating: 1\n",
                  "MAX_LENGTH: 50257\n"
               ]
            }
         ],
         "source": [
            "# test the dataset\n",
            "dataset = ReviewDataset(df, t, max_review_len = max_review_len, max_summary_len = max_summary_len, lower_case = False)\n",
            "\n",
            "data_idx = 45\n",
            "\n",
            "# decode\n",
            "print(f\"Review: {ReviewDataset.detokenize(dataset, dataset[data_idx][0])}\")\n",
            "print(f\"Summary: {ReviewDataset.detokenize(dataset, dataset[data_idx][1])}\")\n",
            "print(f\"Rating: {int(dataset[data_idx][2])}\")\n",
            "\n",
            "# max length is the max index of the vocabulary\n",
            "MAX_LENGTH = t.vocab_size\n",
            "print(f\"MAX_LENGTH: {MAX_LENGTH}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "' # Initialize the tokenizer and model\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\nmodel = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\")\\n\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Define the text you want to embed\\ntext = \"Hello, world!\"\\n\\n# Encode the text using the GPT-2 model\\nembedding, _ = model(tokenizer(text))\\n\\n\\n# Print the shape of the resulting embedding\\n# print(embedding.shape)  # (1, 13, 768) '"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"\"\" # Initialize the tokenizer and model\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "model = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\")\n",
            "\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "\n",
            "# Define the text you want to embed\n",
            "text = \"Hello, world!\"\n",
            "\n",
            "# Encode the text using the GPT-2 model\n",
            "embedding, _ = model(tokenizer(text))\n",
            "\n",
            "\n",
            "# Print the shape of the resulting embedding\n",
            "# print(embedding.shape)  # (1, 13, 768) \"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Model\n",
            "uses context aware word embedding\n",
            "multi-task network\n",
            "\n",
            "Input: takes in a review string\n",
            "Task 1: output a summary string of the input review with a max length defined by the dataset\n",
            "Task 2: output a rating of the input review as a float 0-1\n",
            "\n",
            "Use an encoder decoder setup with one decoder for each task\n",
            "\"\"\"\n",
            "\n",
            "class EncoderRNN(nn.Module):\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        super(EncoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "\n",
            "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
            "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
            "\n",
            "    def forward(self, input, hidden):\n",
            "        print(input.get_device())\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        output = embedded\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "        return output, hidden\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)\n",
            "\n",
            "\n",
            "class AttnDecoderRNN(nn.Module):\n",
            "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
            "        super(AttnDecoderRNN, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "        self.output_size = output_size\n",
            "        self.dropout_p = dropout_p\n",
            "        self.max_length = max_length\n",
            "\n",
            "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
            "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
            "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
            "        self.dropout = nn.Dropout(self.dropout_p)\n",
            "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
            "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
            "\n",
            "    def forward(self, input, hidden, encoder_outputs):\n",
            "        embedded = self.embedding(input).view(1, 1, -1)\n",
            "        embedded = self.dropout(embedded)\n",
            "\n",
            "        attn_weights = nn.softmax(\n",
            "            self.attn(th.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
            "        attn_applied = th.bmm(attn_weights.unsqueeze(0),\n",
            "                                 encoder_outputs.unsqueeze(0))\n",
            "\n",
            "        output = th.cat((embedded[0], attn_applied[0]), 1)\n",
            "        output = self.attn_combine(output).unsqueeze(0)\n",
            "\n",
            "        output = nn.relu(output)\n",
            "        output, hidden = self.gru(output, hidden)\n",
            "\n",
            "        output = nn.log_softmax(self.out(output[0]), dim=1)\n",
            "        return output, hidden, attn_weights\n",
            "\n",
            "    def initHidden(self):\n",
            "        return th.zeros(1, 1, self.hidden_size, device=device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [
            {
               "ename": "RuntimeError",
               "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "Cell \u001b[1;32mIn [40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m hidden_size \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m\n\u001b[1;32m----> 3\u001b[0m encoder1 \u001b[39m=\u001b[39m EncoderRNN(MAX_LENGTH, hidden_size)\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      4\u001b[0m decoder1 \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, MAX_LENGTH, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[39m# single forward pass test\u001b[39;00m\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
                  "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
                  "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
               ]
            }
         ],
         "source": [
            "# test the model\n",
            "hidden_size = 256\n",
            "encoder1 = EncoderRNN(MAX_LENGTH, hidden_size).to(device)\n",
            "decoder1 = AttnDecoderRNN(hidden_size, MAX_LENGTH, dropout_p=0.1).to(device)\n",
            "\n",
            "# single forward pass test\n",
            "input_tensor = dataset[0][0]\n",
            "target_tensor = dataset[0][1]\n",
            "\n",
            "encoder_hidden = encoder1.initHidden()\n",
            "\n",
            "encoder_outputs = th.zeros(MAX_LENGTH, encoder1.hidden_size, device=device)\n",
            "\n",
            "for ei in range(input_tensor.size(0)):\n",
            "    encoder_output, encoder_hidden = encoder1(\n",
            "        input_tensor[ei], encoder_hidden)\n",
            "    encoder_outputs[ei] += encoder_output[0, 0]\n",
            "\n",
            "decoder_input = th.tensor([[]], device=device)  # SOS\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                  "Input length of input_ids is 11, but `max_length` is set to 11. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'input_ids': [1212, 318, 262, 1336, 2420, 326, 345, 765, 284, 35743, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
                  "11\n"
               ]
            },
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'index_select'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [54], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(encoded_prompt[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(inputs[\u001b[39m0\u001b[39m]))\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     22\u001b[0m     inputs,\n\u001b[1;32m     23\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(inputs[\u001b[39m0\u001b[39;49m]) ,  \u001b[39m# Half the length of the encoded input text\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoded_prompt[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOutput: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Print the generated summary\u001b[39;00m\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:1535\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1526\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1527\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1532\u001b[0m )\n\u001b[1;32m   1534\u001b[0m \u001b[39m# 11. expand input_ids with `num_return_sequences` additional sequences per batch\u001b[39;00m\n\u001b[0;32m-> 1535\u001b[0m input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expand_inputs_for_generation(\n\u001b[1;32m   1536\u001b[0m     input_ids,\n\u001b[1;32m   1537\u001b[0m     expand_size\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m   1538\u001b[0m     is_encoder_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mis_encoder_decoder,\n\u001b[1;32m   1539\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1542\u001b[0m \u001b[39m# 12. run sample\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m   1544\u001b[0m     input_ids,\n\u001b[1;32m   1545\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1554\u001b[0m )\n",
                  "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch1.13/lib/python3.10/site-packages/transformers/generation_utils.py:648\u001b[0m, in \u001b[0;36mGenerationMixin._expand_inputs_for_generation\u001b[0;34m(input_ids, expand_size, is_encoder_decoder, attention_mask, encoder_outputs, **model_kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m token_type_ids\u001b[39m.\u001b[39mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39;49mindex_select(\u001b[39m0\u001b[39m, expanded_return_idx)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m is_encoder_decoder:\n\u001b[1;32m    651\u001b[0m     \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'index_select'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "\n",
            "#from pytorch_transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "import torch\n",
            "\n",
            "# Set the device\n",
            "device = \"cpu\"\n",
            "\n",
            "# Load the GPT-2 model and tokenizer\n",
            "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
            "model = model.to(device)\n",
            "\n",
            "# Generate a summary\n",
            "#prompt = \"Airbags are safety devices that are installed in vehicles to protect passengers in the event of a collision. When a collision occurs, sensors detect the impact and deploy the airbag, which inflates quickly to cushion the passengers and prevent them from being thrown forward or to the side. Airbags are typically located in the steering wheel and dashboard for the driver, and in the doors and roof pillars for the passengers. They are designed to deploy in a specific sequence to maximize the protection they provide. Modern airbags use advanced sensors and algorithms to tailor their deployment to the specific type and severity of the collision.\"\n",
            "prompt = \"This is the full text that you want to summarize.\"\n",
            "encoded_prompt = tokenizer(prompt)\n",
            "print(encoded_prompt)\n",
            "inputs = torch.tensor(encoded_prompt[\"input_ids\"]).unsqueeze(0).to(device)\n",
            "\n",
            "outputs = model.generate(\n",
            "    inputs,\n",
            "    max_length=len(inputs) // 2,  # Half the length of the encoded input text\n",
            "    temperature=0.5,\n",
            "    top_k=50,\n",
            "    top_p=0.9,\n",
            "    repetition_penalty=1.0,\n",
            "    do_sample=True,\n",
            "    num_return_sequences=1,\n",
            "    attention_mask=encoded_prompt[\"attention_mask\"],\n",
            ")\n",
            "print(\"Output: \")\n",
            "# Print the generated summary\n",
            "print(tokenizer.decode(outputs[0]))\n",
            "print(f\"The origianl text is {len(encoded_prompt)} tokens long, and the generated summary is {len(outputs[0])} tokens long.\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'list' object has no attribute 'ne'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_text)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Set the attention mask and pad token id\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m attention_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49mne(tokenizer\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     15\u001b[0m pad_token_id \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mpad_token_id\n\u001b[1;32m     17\u001b[0m \u001b[39m# Generate a response from the model\u001b[39;00m\n",
                  "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ne'"
               ]
            }
         ],
         "source": [
            "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
            "\n",
            "# Load the GPT-2 tokenizer\n",
            "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
            "\n",
            "# Load the GPT-2 model\n",
            "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
            "\n",
            "# Encode a text input\n",
            "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
            "input_ids = tokenizer.encode(input_text)\n",
            "\n",
            "# Set the attention mask and pad token id\n",
            "attention_mask = input_ids.(tokenizer.pad_token_id).long()\n",
            "pad_token_id = tokenizer.pad_token_id\n",
            "\n",
            "# Generate a response from the model\n",
            "outputs = model.generate(\n",
            "    input_ids=input_ids,\n",
            "    attention_mask=attention_mask,\n",
            "    pad_token_id=pad_token_id\n",
            ")\n",
            "\n",
            "# Print the encoded text\n",
            "print(outputs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Dataset preparation\n",
            "Use the ReviewDataset to create a DataLoader\n",
            "Splitting the train, validation, and test sets\n",
            "\"\"\"\n",
            "# initialise the dataset\n",
            "dataset = ReviewDataset(df)\n",
            "dataset_size = len(dataset)\n",
            "\n",
            "# shrink dataset for testing\n",
            "dataset_size = 500\n",
            "dataset = th.utils.data.Subset(dataset, range(dataset_size))\n",
            "\n",
            "# split the dataset\n",
            "train_size = int(0.8 * dataset_size)\n",
            "val_size = int(0.1 * dataset_size)\n",
            "test_size = dataset_size - train_size - val_size\n",
            "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
            "\n",
            "# create the dataloaders\n",
            "batch_size = 32\n",
            "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
            "val_loader = th.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
            "test_loader = th.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([32, 18152]) torch.Size([32]) torch.Size([32, 151])\n"
               ]
            }
         ],
         "source": [
            "# test the dataloader\n",
            "train_loader_iter = iter(train_loader)\n",
            "x, y, z = next(train_loader_iter)\n",
            "print(x.shape, y.shape, z.shape)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "Training\n",
            "\"\"\"\n",
            "\"\"\" # initialise the model\n",
            "# take into account if it is a subset of the dataset\n",
            "model = Summariser(dataset.dataset.vocab_size, 256, max_review_len, max_summary_len)\n",
            "model = model.to(device)\n",
            "\n",
            "# define the loss functions\n",
            "loss_fn1 = th.nn.CrossEntropyLoss()\n",
            "loss_fn2 = th.nn.BCELoss()\n",
            "\n",
            "# define the optimiser\n",
            "optimiser = th.optim.Adam(model.parameters(), lr=0.001)\n",
            "\n",
            "# define the number of epochs\n",
            "epochs = 10\n",
            "\n",
            "# train the model\n",
            "for epoch in range(epochs):\n",
            "    for review, rating, summary in train_loader:\n",
            "        # zero the gradients\n",
            "        optimiser.zero_grad()\n",
            "\n",
            "        # forward pass\n",
            "        y_pred1, y_pred2 = model(review)\n",
            "\n",
            "        # calculate the loss\n",
            "        loss1 = loss_fn1(y_pred1, summary)\n",
            "        loss2 = loss_fn2(y_pred2, rating.unsqueeze(1).float())\n",
            "        loss = loss1 + loss2\n",
            "\n",
            "        # backward pass\n",
            "        loss.backward()\n",
            "\n",
            "        # update the weights\n",
            "        optimiser.step()\n",
            "\n",
            "    # print the loss\n",
            "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}') \"\"\"\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.8 64-bit (microsoft store)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.8"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "69323fde9fc4d20886c37f6bdc4a05b4e3b82913212d2329f781a907e0bb44ca"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
